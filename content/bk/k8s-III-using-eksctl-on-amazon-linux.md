---
title: "K8S 3: Using eksctl on Amazon Linux EC2"
date: 2019-11-14T17:16:22+09:00
draft: false
authors: ["hoangmnsd"]
#categories: [Tech-Tutorials]
#tags: [Kubernetes,AWS,eksctl]
comments: true
toc: true
# below props are for the404blog theme
authorImg: "https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/hoangmsnd-avatar001.jpg"
description: "c√°ch 2 l√† d√πng `eksctl` l√† CLI c·ªßa AWS ph√°t tri·ªÉn, nhi·ªám v·ª• t∆∞∆°ng t·ª± nh∆∞ Service EKS, nh∆∞ng ta l√†m vi·ªác v·ªõi n√≥ tr√™n CLI/terminal"
---

# Gi·ªõi thi·ªáu

ƒê·ªÉ v·ªçc Kubernetes tr√™n AWS, c√≥ nhi·ªÅu c√°ch:

c√°ch 1 l√† d√πng Service EKS c·ªßa AWS, l√†m vi·ªác tr√™n Console lu√¥n, r·∫•t tr·ª±c quan

c√°ch 2 l√† d√πng `eksctl` l√† CLI c·ªßa AWS ph√°t tri·ªÉn, nhi·ªám v·ª• t∆∞∆°ng t·ª± nh∆∞ Service EKS, nh∆∞ng ta l√†m vi·ªác v·ªõi n√≥ tr√™n CLI/terminal

c√°ch 3 l√† t·∫°o 1 EC2 Ubuntu 18.04 LTS (t2.medium tr·ªü l√™n), c√†i `minikube` l√™n n√≥, d·ª±ng 1 cluster

=> c√°ch 1 v√† 2 kh√° t·ªën k√©m, nh∆∞ng b·∫°n c√≥ th·ªÉ d√πng full service, g·∫ßn v·ªõi m√¥i tr∆∞·ªùng production nh·∫•t,  
c√°ch 3 th√¨ r·∫ª h∆°n nhi·ªÅu, c√°c b·∫°n ch·ªâ t·ªën ph√≠ duy tr√¨ con EC2 Ubuntu th√¥i, tuy nhi√™n c√°ch n√†y ch·ªâ n√™n d√πng ƒë·ªÉ v·ªçc v·∫°ch, d√πng "cho bi·∫øt" th·∫ø n√†o l√† k8s th√¥i üòÜ

B√†i n√†y m√¨nh s·∫Ω h∆∞·ªõng d·∫´n c√°ch 2, d√πng `eksctl`, c√°c b√†i tr∆∞·ªõc ƒë√£ n√≥i v·ªÅ c√°ch 3 r·ªìi

# Chu·∫©n b·ªã

Launch 1 EC2 Amazon Linux, t2.micro l√† ƒë·ªß, ssh v√†o r·ªìi l√†m vi·ªác

install kubectl

```sh
curl -o kubectl https://amazon-eks.s3-us-west-2.amazonaws.com/1.14.6/2019-08-22/bin/linux/amd64/kubectl
chmod +x ./kubectl
mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc
kubectl version --short --client
```

install¬†aws-iam-authenticator¬†on Linux  
```sh
curl -o aws-iam-authenticator https://amazon-eks.s3-us-west-2.amazonaws.com/1.14.6/2019-08-22/bin/linux/amd64/aws-iam-authenticator
chmod +x ./aws-iam-authenticator
mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$HOME/bin:$PATH
echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc
aws-iam-authenticator help
```

install eksctl
```sh
curl --silent --location "https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
eksctl version
```

set default region, v√† set account Docker Hub
```sh
export AWS_DEFAULT_REGION=us-east-1
export DOCKER_USERNAME=AAAAAAA
export DOCKER_PASSWORD=BBBBBBB
export DOCKER_USER_ID=CCCCCC
```

Use AWS Console, create IAM Role and attach to EC2 with this policy:  

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "iam:CreateInstanceProfile",
                "iam:DeleteInstanceProfile",
                "iam:GetRole",
                "iam:GetInstanceProfile",
                "iam:ListRoleTags",
                "iam:UntagRole",
                "iam:TagRole",
                "iam:RemoveRoleFromInstanceProfile",
                "iam:CreateRole",
                "iam:DeleteRole",
                "iam:AttachRolePolicy",
                "iam:PutRolePolicy",
                "iam:ListInstanceProfiles",
                "iam:AddRoleToInstanceProfile",
                "iam:ListInstanceProfilesForRole",
                "iam:PassRole",
                "iam:CreateServiceLinkedRole",
                "iam:DetachRolePolicy",
                "iam:DeleteRolePolicy",
                "iam:DeleteServiceLinkedRole",
                "ec2:DeleteInternetGateway",
                "iam:GetOpenIDConnectProvider",
                "iam:GetRolePolicy"
            ],
            "Resource": [
                "arn:aws:iam::793459850633:instance-profile/eksctl-*",
                "arn:aws:iam::*:oidc-provider/*",
                "arn:aws:iam::793459850633:role/eksctl-*",
                "arn:aws:ec2:*:*:internet-gateway/*"
            ]
        },
        {
            "Sid": "VisualEditor1",
            "Effect": "Allow",
            "Action": [
                "ec2:AuthorizeSecurityGroupIngress",
                "ec2:DeleteSubnet",
                "ec2:AttachInternetGateway",
                "ec2:DeleteRouteTable",
                "ec2:AssociateRouteTable",
                "ec2:DescribeInternetGateways",
                "elasticloadbalancing:DescribeLoadBalancers",
                "autoscaling:DescribeAutoScalingGroups",
                "ec2:CreateRoute",
                "ec2:CreateInternetGateway",
                "ec2:RevokeSecurityGroupEgress",
                "autoscaling:UpdateAutoScalingGroup",
                "ec2:DeleteInternetGateway",
                "ec2:DescribeKeyPairs",
                "ec2:DescribeRouteTables",
                "ec2:ImportKeyPair",
                "ec2:DescribeLaunchTemplates",
                "ec2:CreateTags",
                "ec2:CreateRouteTable",
                "cloudformation:*",
                "ec2:RunInstances",
                "ec2:DetachInternetGateway",
                "ec2:DisassociateRouteTable",
                "ec2:RevokeSecurityGroupIngress",
                "ec2:DescribeImageAttribute",
                "ec2:DeleteNatGateway",
                "autoscaling:DeleteAutoScalingGroup",
                "ec2:DeleteVpc",
                "ec2:CreateSubnet",
                "ec2:DescribeSubnets",
                "eks:*",
                "autoscaling:CreateAutoScalingGroup",
                "ec2:DescribeAddresses",
                "ec2:DeleteTags",
                "ec2:CreateNatGateway",
                "autoscaling:DescribeLaunchConfigurations",
                "ec2:CreateVpc",
                "ec2:DescribeVpcAttribute",
                "autoscaling:DescribeScalingActivities",
                "ec2:DescribeAvailabilityZones",
                "ec2:CreateSecurityGroup",
                "ec2:ModifyVpcAttribute",
                "ec2:ReleaseAddress",
                "ec2:AuthorizeSecurityGroupEgress",
                "ec2:DeleteLaunchTemplate",
                "ec2:DescribeTags",
                "ec2:DeleteRoute",
                "ec2:DescribeLaunchTemplateVersions",
                "ec2:DescribeNatGateways",
                "ec2:AllocateAddress",
                "ec2:DescribeSecurityGroups",
                "autoscaling:CreateLaunchConfiguration",
                "ec2:DescribeImages",
                "ec2:CreateLaunchTemplate",
                "autoscaling:DeleteLaunchConfiguration",
                "ec2:DescribeVpcs",
                "ec2:DeleteSecurityGroup"
            ],
            "Resource": "*"
        }
    ]
}
```

# C√°ch t·∫°o 1 cluster b·∫±ng eksctl

Create a file `cluster.yaml`

```
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: base-project
  region: us-east-1

availabilityZones: ["us-east-1a", "us-east-1d"]

nodeGroups:
  - name: nodegrp-1
    instanceType: t2.medium
    desiredCapacity: 1
```

Apply above config file to create cluster:

```sh
eksctl create cluster -f cluster.yaml
```
ch·ªù kho·∫£ng 10 ph√∫t v√¨ eks s·∫Ω provision ra network r·∫•t t·ªën time:  

more sample template https://github.com/weaveworks/eksctl/blob/master/examples

Get pods, service, nodes, is running

```sh
kubectl get pods,svc,node -A
```

```
[ec2-user@ip-172-31-84-250 ~]$ kubectl get pods,svc,node -A
NAMESPACE     NAME                              READY   STATUS    RESTARTS   AGE
kube-system   pod/aws-node-6k2qq                1/1     Running   0          3h28m
kube-system   pod/coredns-8455f84f99-rzn44      1/1     Running   0          3h34m
kube-system   pod/coredns-8455f84f99-xw2rv      1/1     Running   0          3h34m
kube-system   pod/kube-proxy-w2t7v              1/1     Running   0          3h28m


NAMESPACE     NAME                     TYPE           CLUSTER-IP       EXTERNAL-IP
              PORT(S)         AGE
default       service/kubernetes       ClusterIP      10.100.0.1       <none>
              443/TCP         3h34m
kube-system   service/kube-dns         ClusterIP      10.100.0.10      <none>
              53/UDP,53/TCP   3h34m  


NAMESPACE   NAME                                  STATUS   ROLES    AGE     VERSION
            node/ip-192-168-62-230.ec2.internal   Ready    <none>   3h28m   v1.14.7-eks-1861c5
```
# Run app micro-service on k8s

clone source v·ªÅ
```sh
cd ~
git clone https://github.com/hoangmnsd/k8s-mastery
```

t·∫°o pod frontend:  
```sh
cd /home/ec2-user/k8s-mastery/resource-manifests
kubectl apply -f sa-frontend-deployment.yaml
```
sau khi apply th√¨ pods v√† services, node nh∆∞ sau:  
```
ip-172-31-84-250 ~]$ kubectl get pods,svc,node -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
default       pod/sa-frontend-54789d8b7d-2whc4   1/1     Running   0          2m36s
default       pod/sa-frontend-54789d8b7d-dbh4p   1/1     Running   0          2m36s
kube-system   pod/aws-node-7t2df                 1/1     Running   0          9m5s
kube-system   pod/coredns-8455f84f99-w8dlf       1/1     Running   0          15m
kube-system   pod/coredns-8455f84f99-xqk2f       1/1     Running   0          15m
kube-system   pod/kube-proxy-xzhwd               1/1     Running   0          9m5s

NAMESPACE     NAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
default       service/kubernetes   ClusterIP   10.100.0.1    <none>        443/TCP         15m
kube-system   service/kube-dns     ClusterIP   10.100.0.10   <none>        53/UDP,53/TCP   15m

NAMESPACE   NAME                                  STATUS   ROLES    AGE    VERSION
            node/ip-192-168-34-208.ec2.internal   Ready    <none>   9m5s   v1.14.7-eks-1861c5

ip-172-31-84-250 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        483M   60K  483M   1% /dev
tmpfs           493M     0  493M   0% /dev/shm
/dev/xvda1      7.9G  2.8G  5.0G  36% /
```

t·∫°o service frondend:  
```sh
kubectl create -f service-sa-frontend-lb.yaml
```
get services:    
```
kubectl get svc -A
NAMESPACE     NAME             TYPE           CLUSTER-IP     EXTERNAL-IP                                                              PORT(S)         AGE
default       kubernetes       ClusterIP      10.100.0.1     <none>                                                                   443/TCP         21m
default       sa-frontend-lb   LoadBalancer   10.100.64.73   a40ec71f8061811ea91b70a830ca64b1-169405131.us-east-1.elb.amazonaws.com   80:31360/TCP    102s
kube-system   kube-dns         ClusterIP      10.100.0.10    <none>                                                                   53/UDP,53/TCP   21m
```

check frontend app tr√™n LB URL: `a40ec71f8061811ea91b70a830ca64b1-169405131.us-east-1.elb.amazonaws.com`

T·∫°o pod v√† service c·ªßa backend logic:  
```sh
cd /home/ec2-user/k8s-mastery/resource-manifests
kubectl apply -f sa-logic-deployment.yaml --record
kubectl apply -f service-sa-logic.yaml
```

get pods, svc:    
```
ip-172-31-84-250 resource-manifests]$ kubectl get pods,svc -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
default       pod/sa-frontend-54789d8b7d-2whc4   1/1     Running   0          19m
default       pod/sa-frontend-54789d8b7d-dbh4p   1/1     Running   0          19m
default       pod/sa-logic-7d7ff8f6dc-r9tcz      1/1     Running   0          118s
default       pod/sa-logic-7d7ff8f6dc-zhwv2      1/1     Running   0          118s
kube-system   pod/aws-node-7t2df                 1/1     Running   0          25m
kube-system   pod/coredns-8455f84f99-w8dlf       1/1     Running   0          31m
kube-system   pod/coredns-8455f84f99-xqk2f       1/1     Running   0          31m
kube-system   pod/kube-proxy-xzhwd               1/1     Running   0          25m

NAMESPACE     NAME                     TYPE           CLUSTER-IP     EXTERNAL-IP                                                              PORT(S)         AGE
default       service/kubernetes       ClusterIP      10.100.0.1     <none>                                                                   443/TCP         31m
default       service/sa-frontend-lb   LoadBalancer   10.100.64.73   a40ec71f8061811ea91b70a830ca64b1-169405131.us-east-1.elb.amazonaws.com   80:31360/TCP    11m
default       service/sa-logic         ClusterIP      10.100.97.45   <none>                                                                   80/TCP          4s
kube-system   service/kube-dns         ClusterIP      10.100.0.10    <none>                                                                   53/UDP,53/TCP   31m
```
T·∫°o pod v√† service c·ªßa backend webapp:  
```sh
cd /home/ec2-user/k8s-mastery/resource-manifests
kubectl apply -f sa-web-app-deployment.yaml --record
kubectl apply -f service-sa-web-app-lb.yaml
```

get pods,svc:    
```
ip-172-31-84-250 resource-manifests]$ kubectl get pods,svc -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
default       pod/sa-frontend-54789d8b7d-2whc4   1/1     Running   0          21m
default       pod/sa-frontend-54789d8b7d-dbh4p   1/1     Running   0          21m
default       pod/sa-logic-7d7ff8f6dc-r9tcz      1/1     Running   0          4m8s
default       pod/sa-logic-7d7ff8f6dc-zhwv2      1/1     Running   0          4m8s
default       pod/sa-web-app-5f7d8fd94d-lbzj8    1/1     Running   0          27s
default       pod/sa-web-app-5f7d8fd94d-ql5k2    1/1     Running   0          27s
kube-system   pod/aws-node-7t2df                 1/1     Running   0          27m
kube-system   pod/coredns-8455f84f99-w8dlf       1/1     Running   0          33m
kube-system   pod/coredns-8455f84f99-xqk2f       1/1     Running   0          33m
kube-system   pod/kube-proxy-xzhwd               1/1     Running   0          27m

NAMESPACE     NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP                                                              PORT(S)         AGE
default       service/kubernetes       ClusterIP      10.100.0.1      <none>                                                                   443/TCP         33m
default       service/sa-frontend-lb   LoadBalancer   10.100.64.73    a40ec71f8061811ea91b70a830ca64b1-169405131.us-east-1.elb.amazonaws.com   80:31360/TCP    13m
default       service/sa-logic         ClusterIP      10.100.97.45    <none>                                                                   80/TCP          2m14s
default       service/sa-web-app-lb    LoadBalancer   10.100.34.198   a289bb56f061a11ea86df120e903ee59-714828784.us-east-1.elb.amazonaws.com   80:32321/TCP    5s
kube-system   service/kube-dns         ClusterIP      10.100.0.10     <none>                                                                   53/UDP,53/TCP   33m
```

s·ª≠a c√°i App.js ƒë·ªÉ n√≥ fetch URL c·ªßa sa-webapp
```sh
nano ~/k8s-mastery/sa-frontend/src/App.js
```

s·ª≠a nh∆∞ sau (d√πng ELB URL c·ªßa sa-webapp):  
```
fetch('http://a7cf3208e067911ea90de1247d6da376-1135942870.us-east-1.elb.amazonaws.com/sentiment', {
```

build docker images v√† push l·∫°i l√™n Docker Hub:  
```sh
npm run build
sudo docker build -f Dockerfile -t $DOCKER_USER_ID/sentiment-analysis-frontend:28 .
sudo docker push $DOCKER_USER_ID/sentiment-analysis-frontend:28
```

s·ª≠a deployment config ƒë·ªÉ d√πng image m·ªõi tag:28  
```sh
nano ~/k8s-mastery/resource-manifests/sa-frontend-deployment-update.yaml
```
s·ª≠a ch·ªó image th√†nh d√πng b·∫£n tag :28,  
c·∫ßn ch√∫ √Ω ch·ªó `hoangmnsd` ƒë√≥ l√† account Docker Hub c·ªßa m√¨nh, b·∫°n c·∫ßn d√πng account Docker Hub c·ªßa b·∫°n, v√≠ d·ª• l√† `CCCCCC` m√† b·∫°n ƒë√£ setting ·ªü tr√™n

```
image: hoangmnsd/sentiment-analysis-frontend:28
```

apply l·∫°i:  
```sh
kubectl apply -f sa-frontend-deployment-update.yaml  --record
```

check l·∫°i app ƒë·ªÉ th√¥ng lu·ªìng t·ª´ frontend -> backend:  
`a40ec71f8061811ea91b70a830ca64b1-169405131.us-east-1.elb.amazonaws.com`

# SSH v√†o Node trong Cluster

N·∫øu mu·ªën c√≥ th·ªÉ ssh v√†o Node, tr∆∞·ªõc ti√™n c·∫ßn t·∫°o ssh key `ssh-keygen`:  

```
ip-172-31-84-250 ~]$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/ec2-user/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/ec2-user/.ssh/id_rsa.
Your public key has been saved in /home/ec2-user/.ssh/id_rsa.pub.
```

khi t·∫°o cluster c·∫ßn t·∫°o v·ªõi file config nh∆∞ sau:  
```
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: base-project
  region: us-east-1

availabilityZones: ["us-east-1a", "us-east-1d"]

nodeGroups:
  - name: nodegrp-1
    instanceType: t2.medium
    desiredCapacity: 1
    ssh: # import public key from file
      publicKeyPath: /home/ec2-user/.ssh/id_rsa.pub
```

Khi ssh v√†o th√¨ d√πng command sau:
```sh
ssh -i ~/.ssh/id_rsa ec2-user@<EC2-PUBLIC-IP>
```

# T·∫°o k8s dashboard  

Do m√¨nh d√πng b·∫£n recommend b·ªã ko v√†o dc t·ª´ windows browser, n√™n d√πng b·∫£n alternative: 

```sh
kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta5/aio/deploy/alternative.yaml
```

t·∫°o `serviceaccount`:  
```sh
kubectl create serviceaccount my-dashboard-sa -n kubernetes-dashboard
```

t·∫°o `clusterrolebinding`:  
```sh
kubectl create clusterrolebinding my-dashboard-sa \
--clusterrole=cluster-admin \
--serviceaccount=kubernetes-dashboard:my-dashboard-sa
```

get secret:  
```sh
kubectl get secrets -n kubernetes-dashboard
```

L·∫•y token:  
```sh
kubectl describe secret -n kubernetes-dashboard <TOKEN_NAME>
```

d√πng extension `REQUESTLY` c·ªßa Chrome, link c√†i:  
`https://chrome.google.com/webstore/detail/requestly-redirect-url-mo/mdnleldcmiljblolnjhpnblkcekpdkpa`
config nh∆∞ h√¨nh sau, m·ªói khi v√†o c√°i IP kia th√¨ n√≥ s·∫Ω t·ª± ƒë·ªông modify Header v√† add th√™m TOKEN v√†o cho m√¨nh  
![](https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/k8s-dashboard-requestly.jpg)

port-forward ƒë·ªÉ b√™n ngo√†i c√≥ th·ªÉ access:  
```sh
kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 9090:80 --address 0.0.0.0
```

Done! B·∫°n s·∫Ω v√†o ƒë∆∞·ª£c k8s Dashboard t·ª´ Chrome browser tr√™n windows v·ªõi link `http://<EC-PUBLIC-IP>:9090`

# L·ªói c√≥ th·ªÉ g·∫∑p

Sau khi install helm v√† app spring postgres,  
sau ƒë√≥ th√™m k8s dashboard th√¨ b·ªã l·ªói POD m·ªõi t·∫°o lu√¥n ·ªü tr·∫°ng th√°i `ContainerCreating`

xem logs:  
```sh
kubectl describe pod <pod_name> 
```

th√¨ ph√°t hi·ªán l·ªói network: `add cmd: failed to assign an IP address to container`

google 1 l√∫c th√¨ th·∫•y (https://github.com/aws/amazon-vpc-cni-k8s/issues/59),  
nguy√™n nh√¢n c√≥ th·ªÉ do thi·∫øu IP trong ENI  

"After checking AWS documentation, it seems that there is an IP limit per instance: 18 for t3.medium, 36 for t3.large"

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html
