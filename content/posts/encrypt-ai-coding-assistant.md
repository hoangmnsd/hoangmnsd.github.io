---
title: "Setting up AI coding assistant"
date: 2024-07-26T21:56:40+07:00
draft: false
authors: ["hoangmnsd"]
categories: [Tech-Tutorials]
tags: [Extension,AI,Agent,LLM]
comments: true
toc: true
# below props are for the404blog theme
authorImg: "https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/hoangmsnd-avatar001.jpg"
description: "BÃ i nÃ y giá»›i thiá»‡u vá» 1 tool AI coding assistant ráº¥t thÃº vá»‹..."
---

TÆ°Æ¡ng lai cÃ´ng viá»‡c cá»§a Developer sáº½ "nhÃ n" Ä‘i ráº¥t nhiá»u.. vÃ  cÅ©ng **cáº¡nh tranh** hÆ¡n ráº¥t nhiá»u vá»›i sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c cÃ´ng cá»¥ AI Coding assistant/agent nhÆ° tháº¿ nÃ y...

Báº¡n hoÃ n toÃ n cÃ³ thá»ƒ "ra chuá»“ng gÃ " náº¿u ko xuÃ´i mÃ¬nh theo dÃ²ng cháº£y cá»§a thá»i Ä‘áº¡i.

# 1. Mentat (dá»«ng update tá»« thÃ¡ng 4/2024)

## 1.1. Overview

MÃ¬nh Ä‘Æ°á»£c biáº¿t Ä‘áº¿n [mentat](https://github.com/AbanteAI/mentat) qua 1 repo nÃ o Ä‘Ã³ vá» ChatGPT.

Mentat open source vÃ  báº¡n sáº½ sá»­ dá»¥ng OpenAI API key Ä‘á»ƒ cung cáº¥p cho nÃ³.

Báº¡n cho nÃ³ Ä‘á»c 1 sá»‘ file code cá»§a báº¡n lÃ  input Ä‘áº§u vÃ o, sau Ä‘Ã³ báº¡n chat vá»›i nÃ³ trÃªn terminal, nÃ³ sáº½ giÃºp báº¡n code luÃ´n ğŸ˜€

## 1.2. Setup Mentat trÃªn Windows + GitBash + VS Code

Download python3.11 (trÃªn 3.10 lÃ  OK) vá»

https://www.python.org/downloads/release/python-3119/

CÃ i Ä‘áº·t (Khi cÃ i thÃ¬ nhá»› tick chá»n vÃ o chá»— add/export to PATH env variable)

Verify xem `python.exe` cÃ³ tá»“n táº¡i trong folder nÃ y ko:

`C:\Users\<USER_NAME_Cá»¦A_Báº N>\AppData\Local\Programs\Python\Python311\python.exe`

Má»Ÿ Gitbash, chuyá»ƒn version máº·c Ä‘á»‹nh sang python3.11 má»›i download vá»:

```sh
cd ~

nano .bashrc

# Sá»­a file thÃªm dÃ²ng sau:
alias python='winpty "C:\Users\<USER_NAME_Cá»¦A_Báº N>\AppData\Local\Programs\Python\Python311\python.exe"'
# ÄÃ³ng file save láº¡i

source .bashrc

# Check láº¡i xem Ä‘Ãºng chuyá»ƒn sang version má»›i chÆ°a
python --version
```

Trong Gitbash, install pip, ko cÃ³ lá»—i gÃ¬ lÃ  ok:

```sh
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py

python get-pip.py
```

Trong Gitbash activate venv, install mentat:

```sh
# (optional) Báº¡n cÃ³ thá»ƒ create venv hoáº·c ko. MÃ¬nh suggest lÃ  ko cáº§n
# VÃ¬ khi táº¡o .venv, báº¡n cáº§n táº¡o thÃªm gitignore Ä‘á»ƒ mentat ko dÃ¹ng folder .venv lÃ m input Ä‘áº§u vÃ o. NhÆ° váº­y sáº½ tá»‘n nhiá»u tiá»n cá»§a OpenAI key.
python -m venv .venv
source .venv/Scripts/activate

python -m pip install git+https://github.com/AbanteAI/mentat.git
```

Hiá»‡n khi sá»­ dá»¥ng mentat mÃ¬nh Ä‘ang bá»‹ lá»—i:

```
USER_NAME_Cá»¦A_Báº N@AAA-BBB MINGW64 C:/Users/USER_NAME_Cá»¦A_Báº N/AppData/Local/Programs/Microsoft VS Code (master)
$ mentat
bash: mentat: command not found
```

ThÃ¬ hÃ£y thÃªm command sau Ä‘á»ƒ mentat cÃ³ trong env PATH:

```s
export PATH=$PATH:/c/Users/<USER_NAME_Cá»¦A_Báº N>/AppData/Local/Programs/Python/Python311/Scripts
```

Giá» add OpenAPI key vÃ o Ä‘á»ƒ mentat sá»­ dá»¥ng:

```sh
export OPENAI_API_KEY=<your key here>
```

Giá» gÃµ mentat tÃªn cÃ¡c file input Ä‘áº§u vÃ o cho nÃ³ Ä‘á»c. Sau Ä‘Ã³ chat vá»›i nÃ³ thÃ´i.

Báº¡n cÃ³ thá»ƒ Ä‘Æ°a cáº£ folder cho nÃ³ Ä‘á»c cÅ©ng Ä‘Æ°á»£c. NhÆ°ng Ä‘iá»u Ä‘Ã³ Ä‘á»“ng nghÄ©a vá»›i viá»‡c báº¡n ko quáº£n lÃ½ sá»‘ lÆ°á»£ng input Ä‘áº§u vÃ o cho mentat. Khiáº¿n key cá»§a báº¡n cÃ³ thá»ƒ háº¿t tiá»n nhanh hÆ¡n.

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-assist-mentat-01.jpg)

Hiá»‡n táº¡i cÃ³ 1 váº¥n Ä‘á» nhá», lÃ  mentat chá»‰ cÃ³ thá»ƒ sá»­a code 1 file táº¡i 1 thá»i Ä‘iá»ƒm. Náº¿u báº¡n yÃªu cáº§u nÃ³ sá»­a code 2 file, nÃ³ in ra cÃ¢u tráº£ lá»i nhÆ°ng khi báº¡n áº¥n `Apply change` nÃ³ sáº½ chá»‰ sá»­a 1 file.

VÃ  1 váº¥n Ä‘á» to, lÃ  Mentat ko support/kÃ©m support cÃ¡c OpenAI model khÃ¡c (gpt-4o-mini/gpt-4o) vÃ  Opensource Model nhÆ° Ollama.

# 2. Github Copilot

TÆ°Æ¡ng tá»± nhÆ° Mentat nhÆ°ng báº¡n tráº£ tiá»n trá»±c tiáº¿p cho Github. 10$ per month. DÃ¹ng thá»­ 30 days.

Báº¡n viáº¿t comment trong code vÃ  áº¥n Ctr+I Ä‘á»ƒ há»i nÃ³ trá»±c tiáº¿p trong file code.

{{< youtube Fi3AJZZregI >}}

https://www.youtube.com/watch?v=Fi3AJZZregI&list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt&ab_channel=VisualStudioCode

https://www.youtube.com/watch?v=aGbfU4GiI9s&ab_channel=Ph%E1%BA%A1mHuyHo%C3%A0ng


# 3. Amazon Q Developer

https://aws.amazon.com/q/developer/pricing/

CÃ³ tier Free giá»›i háº¡n: limit 50 interactions per month

Video giá»›i thiá»‡u: https://www.youtube.com/watch?v=i0zQpJPfSdU&ab_channel=AWSDevelopers

{{< youtube i0zQpJPfSdU >}}


# 4. ContinueDev (Recommend)

## 4.1. Overview

So vá»›i Mentat thÃ¬ mÃ¬nh tháº¥y cÃ¡i nÃ y tá»‘t hÆ¡n nhiá»u, Link github: https://github.com/continuedev/continue

Quan trá»ng nháº¥t lÃ  nÃ³ xá»­ lÃ½ Ä‘Æ°á»£c váº¥n Ä‘á» cá»§a Mentat lÃ  ko dÃ¹ng Ä‘Æ°á»£c cÃ¡c OpenAI model khÃ¡c nhÆ° (gpt-4o, gpt-4o-mini), sau Ä‘Ã³ lÃ  cÃ³ thá»ƒ dÃ¹ng cÃ¡c Ollama model ná»¯a.

## 4.2. Setup ContinueDev vá»›i nhiá»u endpoint khÃ¡c nhau

Sau khi Ä‘Ã£ install VS Code extension.

Sá»­a file `C:\Users\YOUR_USER_NAME\.continue\config.json` Ä‘á»ƒ káº¿t ná»‘i vá»›i OpenAI gpt-4o-mini:
```json
{
  "models": [
    {
      "title": "GPT-4o-mini",
      "provider": "openai",
      "model": "gpt-4o-mini",
      "apiKey": "sk-proj-XXX"
    }
  ]
```

Sá»­a file `C:\Users\YOUR_USER_NAME\.continue\config.json` Ä‘á»ƒ káº¿t ná»‘i vá»›i Ollama cá»§a cÃ¡ nhÃ¢n (káº¿t há»£p Ollama vá»›i https://github.com/ParisNeo/ollama_proxy_server Ä‘á»ƒ cÃ³ apiKey):
```json
{
  "models": [
    {
      "title": "llama3.1",
      "provider": "ollama",
      "model": "llama3.1",
      "apiKey": "user1:ABC",
      "apiBase": "https://ollamaproxy.[YOUR_DOMAIN].duckdns.org/"
    }
  ],
```

RiÃªng Perplexity thÃ¬ há» ko expose háº¿t api nÃªn sáº½ bá»‹ lá»—i. Náº¿u config trá» Ä‘áº¿n Perplexity sáº½ bá»‹ lá»—i do perplexity chá»‰ má»Ÿ api cho `/chat/completions` thÃ´i:
```json
{
  "models": [
    {
      "title": "llama-3.1-8b-instruct",
      "provider": "openai",
      "model": "llama-3.1-8b-instruct",
      "apiKey": "pplx-xxx",
      "apiBase": "https://api.perplexity.ai"
    }
  ],
```

Lá»—i hiá»‡n táº¡i khi káº¿t ná»‘i Perplexity:
```
Error streaming diff: Error: HTTP 400 Bad Request from https://api.perplexity.ai/completions {"error":{"message":"The model should only be queried with the /chat/completions endpoint.","type":"invalid_model","code":400}}
```

CÃ³ thá»ƒ dÃ¹ng ctrl+L Ä‘á»ƒ chat vá»›i Perplexity, nhÆ°ng ko dÃ¹ng Ä‘Æ°á»£c Ctrl+I vÃ¬ nÃ³ Ä‘ang trá» Ä‘áº¿n path khÃ¡c.

Náº¿u sá»­a `apiBase=https://api.perplexity.ai/chat/` Ä‘á»ƒ dÃ¹ng thá»­ Ctrl+I thÃ¬ váº«n lá»—i:
```
Error streaming diff: Error: HTTP 400 Bad Request from https://api.perplexity.ai/chat/completions {"error":{"message":"[\"At body -> messages: Field required\"]","type":"bad_request","code":400}}
```

TÃºm láº¡i, hiá»‡n táº¡i chá»‰ cÃ³ thá»ƒ dÃ¹ng ContinueDev Vá»›i OpenAI (cÃ¡c model) vÃ  Ollama (pháº£i Ä‘i kÃ¨m ollama_proxy_server Ä‘á»ƒ cÃ³ apikey)

## 4.3. Thá»­ tabAutocompleteModel dÃ¹ng model Ollama starcoder:1b

Chá»— file `C:\Users\YOUR_USER_NAME\.continue\config.json`, `tabAutocompleteModel` nÃªn dÃ¹ng theo recommend sau:
https://docs.continue.dev/features/tab-autocomplete

Hiá»‡n táº¡i thÃ¬ mÃ¬nh dÃ¹ng ContnueDev vá»›i chá»©c nÄƒng Ctrl+I vÃ  Ctrl+L thÃ´i, Ä‘ang disable chá»©c nÄƒng `tabAutocomplete` nÃ y vÃ¬ nghÄ© nÃ³ sáº½ spam OpenAI API lÃ m tá»‘n tiá»n.

Sau khi sá»­ dá»¥ng Tabby, mÃ¬nh tháº¥y chá»©c nÄƒng ráº¥t hay cá»§a Tabby lÃ  Autocomplete ráº¥t nhanh. MÃ¬nh nghÄ© cÃ³ thá»ƒ do nÃ³ dÃ¹ng model `starcoder:1b` nháº¹ ~800Mb nÃªn nhanh váº­y/

NÃªn mÃ¬nh cÃ³ Ã½ tÆ°á»Ÿng lÃ : Deploy model `starcoder:1b` trÃªn Ollama rá»“i cho ContinueDev sá»­ dá»¥ng thá»­. Sá»­a file `C:\Users\YOUR_USER_NAME\.continue\config.json`:

```json
"tabAutocompleteModel": [
    {
      "title": "starcoder:1b",
      "provider": "ollama",
      "model": "starcoder:1b",
      "apiBase": "https://YOUR_OLLAMA_SERVER.org/",
      "apiKey": "user:pass"
    }
  ],
```

NhÆ°ng káº¿t quáº£ lÃ  Ollama trÃªn server cá»§a mÃ¬nh pháº£i xá»­ lÃ½ request liÃªn tá»¥c bá»‹ 100% CPU ğŸ¤£ tab auto ráº¥t cháº­m...

NhÆ° váº­y lÃ  ContinueDev Ä‘Ã nh disable chá»©c nÄƒng tabAutocomplete thÃ´i. ğŸ˜ª

Äá»c thÃªm vá» config: https://docs.continue.dev/setup/configuration

# 5. GPT Pilot

https://github.com/Pythagora-io/gpt-pilot

Demo cÃ³ váº» ráº¥t hay nhÆ°ng ko tháº¥y dÃ¹ng Ä‘Æ°á»£c OpenAI API key, cá»© báº¯t Subscribe Pythgora Pro má»›i cho chat.

CÃ³ docs vá» dÃ¹ng vá»›i my own OpenAI key: https://github.com/Pythagora-io/gpt-pilot/wiki/Using-Pythagora-with-your-own-OpenAI-key

NhÆ°ng dÃ¹ config Ä‘Ãºng váº«n ko dÃ¹ng Ä‘Æ°á»£c. MÃ¬nh chá»‹u bá» qua luÃ´n.

NgoÃ i ra cÃ²n báº¯t login account pythagora nÃªn cÃ ng Ã¡c cáº£m.

# 6. ChatDev

https://github.com/OpenBMB/ChatDev

Ã½ tÆ°á»Ÿng khÃ¡ hay khi táº¡o 1 cÃ´ng ty thu nhá», má»—i model Ä‘áº£m nhiá»‡m 1 role nhÆ° CEO, CTO, programmer, tester, designer. ChÃºng sáº½ tá»± nÃ³i chuyá»‡n vá»›i nhau Ä‘á»ƒ táº¡o ra sáº£n pháº©m ğŸ¤£

CÃ¡i nÃ y thá»±c sá»± lÃ m mÃ¬nh áº¥n tÆ°á»£ng vá» cÃ¡ch há» dÃ¹ng ChatGPT Ä‘á»ƒ táº¡o ra sáº£n pháº©m

## 6.1. Run on WSL Ubuntu 22.04

```s
git clone https://github.com/OpenBMB/ChatDev.git

python3.10 -m venv venv

source venv/bin/activate

cd ChatDev/
pip3 install -r requirements.txt
export OPENAI_API_KEY="your_OpenAI_API_key"

python3 run.py --task "create a flabby bird game web application runing in javascript" --name "FlabbyBirdHoangmnsd"

python3 run.py --task "using python, create a web application to chat with chatGPT using exist OPENAI API Key" --name "ChatWithGPT"
```

Chá»‰ cáº§n ngáº¯n gá»n nhÆ° váº­y thÃ´i, ChatDev sáº½ chia thÃ nh cÃ¡c role nhÆ° CEO, CTO, programmer, tester, blabla Ä‘á»ƒ tá»± tháº£o luáº­n vá»›i nhau vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i cho báº¡n.

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished.jpg)

## 6.2 Run application táº¡o bá»Ÿi ChatDev

Code sáº½ náº±m trong folder nÃ y `WareHouse`: 

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product.jpg)

Giá» mÃ¬nh lÃ m theo hÆ°á»›ng dáº«n trong file `WareHouse/<PROJECT_NAME>/manual.md`

Náº¿u gáº·p lá»—i kiá»ƒu nÃ y:

```s
$ python3.10 main.py
 * Serving Flask app 'main' (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
Permission denied
```

NguyÃªn nhÃ¢n lÃ  do MÃ¡y mÃ¬nh ko Ä‘Æ°á»£c phÃ©p run trÃªn port 5000, HÃ£y sá»­a code thÃ nh Flask cháº¡y trÃªn port 8001 cháº³ng háº¡n:

```py
if __name__ == '__main__':
    app.run(host="0.0.0.0", port=8001, debug=True)
```

Náº¿u gáº·p lá»—i kiá»ƒu nÃ y:

```s
jinja2.exceptions.TemplateNotFound: index.html
```

CÃ³ nghÄ©a lÃ  Flask Ä‘ang tÃ¬m html file trong folder `templates/index.html`. HÃ£y táº¡o folder vÃ  cho file vÃ o Ä‘Ã³.

App Ä‘ang run á»Ÿ port 8001:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run1.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run2.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run3.jpg)

Trong quÃ¡ trÃ¬nh run app cá»§a ChatDev táº¡o ra, báº¡n cÃ³ thá»ƒ gáº·p nhiá»u lá»—i khÃ¡c nhau (2 lá»—i nhÆ° mÃ¬nh Ä‘Ã£ liá»‡t kÃª bÃªn trÃªn). VÃ  1 sá»‘ lá»—i liÃªn quan Ä‘áº¿n code kiá»ƒu API ko cÃ²n support nhÆ°ng ChatDev váº«n dÃ¹ng. (https://stackoverflow.com/a/76027573). 

Äiá»u nÃ y cÃ³ thá»ƒ tháº¥y lÃ  do ChatDev váº«n Ä‘ang dÃ¹ng nhÆ°ng kiáº¿n thá»©c cÅ©, chÆ°a cáº­p nháº­t láº¯m. 

Tuy nhiÃªn Ã½ tÆ°á»Ÿng lÃ  ráº¥t tÃ¡o báº¡o. 
Trong Ä‘iá»u kiá»‡n hoÃ n háº£o (Ko cÃ³ kiáº¿n thá»©c nÃ o cá»§a ChatDev dÃ¹ng bá»‹ outdate, ko cÃ³ lá»—i mÃ´i trÆ°á»ng tá»« phÃ­a báº¡n) Báº¡n hoÃ n toÃ n cÃ³ thá»ƒ tá»‘n dÆ°á»›i 1$ cho 1 pháº§n má»m. RÃºt ngáº¯n quÃ¡ trÃ¬nh táº¡o pháº§n má»m Ä‘Ã¡ng ká»ƒ.

## 6.3. Review quÃ¡ trÃ¬nh ChatDev táº¡o ra sáº£n pháº©m

DÃ¹ng command sau;

```py
python ChatDev/visualizer/app.py
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chatvisualizer.jpg)

báº¡n upload file .log trong foldedr cá»§a project lÃªn lÃ  tháº¥y:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay.jpg)

Báº¡n sáº½ tháº¥y cÃ¡c con bot chat vá»›i nhau nhÆ° tháº¿ nÃ o Ä‘á»ƒ táº¡o ra sáº£n pháº©m

CEO chat gÃ¬, CPO (Product Owner) rá»“i CTO chat ntn, Programmer, Code Reviewer, Counselor, Designer....

1 cuá»™c nÃ³i chuyá»‡n chÃ¢n thá»±c ğŸ¤£ğŸ¤£

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay-2.jpg)

Code Reviewer tÃ¬m ra lá»—i:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay-3.jpg)

Náº¿u báº¡n muá»‘n Ä‘á»c ká»¹ hÆ¡n cÃ¡c option thÃ¬ Ä‘á»c á»Ÿ Ä‘Ã¢y: https://github.com/OpenBMB/ChatDev/blob/main/wiki.md

```
usage: run.py [-h] [--config CONFIG] [--org ORG] [--task TASK] [--name NAME] [--model MODEL]

argparse

optional arguments:
  -h, --help       show this help message and exit
  --config CONFIG  Name of config, which is used to load configuration under CompanyConfig/; Please see CompanyConfig Section below
  --org ORG        Name of organization, your software will be generated in WareHouse/name_org_timestamp
  --task TASK      Prompt of your idea
  --name NAME      Name of software, your software will be generated in WareHouse/name_org_timestamp
  --model MODEL    GPT Model, choose from {'GPT_3_5_TURBO','GPT_4','GPT_4_32K'}
```

Hiá»‡n ChatDev chÆ°a há»— trá»£ gpt-4o gpt-4o-mini. Chá»n GPT_4 sáº½ khÃ¡ Ä‘áº¯t khi 1 project nhá» cÅ©ng máº¥t hÆ¡n 1$

Äá»‘i vá»›i ChatDev do nhu cáº§u sá»­ dá»¥ng vÃ  view file nhiá»u nÃªn mÃ¬nh nghÄ© nÃªn dÃ¹ng ChatDev run báº±ng GitBash. Ko nÃªn run báº±ng WSL. 

## 6.4. Troubleshoot

Trong quÃ¡ trÃ¬nh install ChatDev, Hiá»‡n cÃ³ thá»ƒ báº¡n sáº½ gáº·p lá»—i kiá»ƒu nÃ y: 
```s
TypeError: init() got an unexpected keyword argument 'refusal'
```
CÃ¡ch fix workaround táº¡m thá»i: https://github.com/OpenBMB/ChatDev/issues/413#issuecomment-2283267043

# 7. Localpilot

https://github.com/danielgross/localpilot/issues/12

Proxy tá»« Github Copilot sang cÃ¡c local model, NhÆ°ng váº«n báº¯t login Github mÃ¬nh tháº¥y hÆ¡i nguy hiá»ƒm.

# 8. Lunary

https://github.com/lunary-ai/lunary

Ã½ tÆ°á»›ng khÃ¡ hay, monitor sá»‘ lÆ°á»£ng request token, cost, Ä‘á»™ trá»…, log, cá»§a cÃ¡c LLM models.

Ko háº³n lÃ  AI Coding Agent, mÃ  giá»‘ng nhÆ° 1 tool Ä‘á»ƒ monitoring.

# 9. Swirl

https://github.com/swirlai/swirl-search

Ã½ tÆ°á»Ÿng lÃ  DÃ¹ng Ä‘á»ƒ táº¡o 1 web ui cho search. TÃ i liá»‡u sáº½ lÃ  Notes/docs/code cá»§a cÃ¡ nhÃ¢n... giá»‘ng google, ms365, openai. nhÆ°ng dÃ¹ng Ä‘á»ƒ search tÃ i liá»‡u cá»§a báº¡n

Ko háº³n lÃ  AI Coding Agent, mÃ  giá»‘ng nhÆ° 1 tool search nhá»‰?

# 10. Tabby

https://tabby.tabbyml.com/docs/quick-start/installation/docker-compose/

## 10.1. Overview

cÅ©ng lÃ  kiá»ƒu AI Coding agent cá»§a VS Code, run open source model locally.

Æ¯u Ä‘iá»ƒm:
- Pháº£n há»“i nhanh, mÃ¬nh cáº£m tháº¥y khÃ¡ báº¥t ngá» vÃ¬ tá»‘c Ä‘á»™ dÃ¹ chá»‰ cháº¡y CPU mode.
- Document khÃ¡ clear.
- CÃ³ support trÃªn nhiá»u platform khÃ¡c nhau (AWS, SkyPilot, Huggingface Space, BentoCloud, Modal... cÃ³ nÃ³i rÃµ).
- CÃ³ support nhiá»u kiá»ƒu install: Linux binary file, Docker container, Windows exe.
- CÃ³ support nhiá»u OS: Windows, WSL, Linux, Macos.
- CÃ³ support cáº£ GPU vÃ  CPU.

NhÆ°á»£c Ä‘iá»ƒm:
- Docker arm64 chÆ°a support https://github.com/TabbyML/tabby/issues/623.
- (? not sure ?) 
  Äá»c issue nÃ y tháº¥y Tabby chá»‰ tá»± run model, ko cÃ³ Ã½ Ä‘á»‹nh sá»­ dá»¥ng cÃ¡c external endpoint nhÆ° OpenAI, Ollama: https://github.com/TabbyML/tabby/issues/795.
  nhÆ°ng láº¡i cÃ³ docs nÃ y nÃ³i vá» OpenAI, Ollama https://tabby.tabbyml.com/docs/references/models-http-api/openai/ (MÃ¬nh lÃ m theo thÃ¬ ko Ä‘c)
- Hiá»‡n mÃ¬nh install váº«n Ä‘ang bá»‹ lá»—i báº£n docker WSL (CPU mode): https://github.com/TabbyML/tabby/discussions/2867

Hiá»‡n minh Ä‘ang install báº£n binary file trÃªn WSL Ubuntu 22.04. Cháº¡y khÃ¡ nhanh.

## 10.2. Install Tabby binary file trÃªn Windows WSL ubuntu 22.04

theo guide https://tabby.tabbyml.com/docs/quick-start/installation/linux/#download-the-release

```sh
sudo apt-get install libgomp1
cd ~/test-tabby/
wget https://github.com/TabbyML/tabby/releases/download/nightly/tabby_x86_64-manylinux2014.zip
mkdir tabby-binary/
unzip -d tabby-binary/ tabby_x86_64-manylinux2014.zip

# direct to binary files

chmod +x tabby llama-server
# For CPU-only environments
./tabby serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct
```

log OK:
```
  As an open source project, we collect usage statistics to inform development priorities. For more
  information, read https://tabby.tabbyml.com/docs/configuration#usage-collection

  We will not see or any code in your development process.

  Welcome to Tabby!

  If you have any questions or would like to engage with the Tabby team, please join us on Slack
  (https://links.tabbyml.com/join-slack-terminal).



â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•šâ–ˆâ–ˆâ•”â•
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•    â•šâ•â•

ğŸ“„ Version 0.16.0-dev.0
ğŸš€ Listening at http://0.0.0.0:8080



  JWT secret is not set

  Tabby server will generate a one-time (non-persisted) JWT secret for the current process.
  Please set the TABBY_WEBSERVER_JWT_TOKEN_SECRET environment variable for production usage.

```

Rá»“i trÃªn Window Powershell get WSL ip: `wsl hostname -I` hoáº·c `wsl hostname -i` vÃ­ dá»¥ láº¥y Ä‘Æ°á»£c `172.27.45.193`

Rá»“i má»Ÿ Chrome sáº½ access Ä‘Æ°á»£c tabby qua port 8080: http://172.27.45.193:8080

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-sign-up-screen.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-sign-up-screen-2.jpg)

account: user/password

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-dashboard.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-dashboard-chat.jpg)

Báº¡n cÃ³ thá»ƒ chat vá»›i nÃ³ luÃ´n. Tráº£ lá»i khÃ¡ nhanh, cÃ³ láº½ vÃ¬ dÃ¹ng model `Qwen2-1.5B-Instruct`? Chá»© mÃ¬nh cháº¡y Lmstudio chat vá»›i nÃ³ cháº­m vl.

VÃ o setting Ä‘á»ƒ xem cÃ³ ráº¥t nhiá»u feature thÃº vá»‹:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-system-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-joib-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-report-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-act-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-general-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-mem-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-subs-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-context-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-sso-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-mail-info.jpg)

TrÃªn VS Code install Tabby extension, rá»“i vÃ o Ä‘Ã¢y update token vÃ  endpoint url:
`C:\Users\USER_NAME\.tabby-client\agent\config.toml`
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config.jpg)

DÃ¹ sá»­a á»Ÿ file `config.toml`, nhÆ°ng vÃ o VS Code, nhÃ¬n gÃ³c dÆ°á»›i bÃªn pháº£i vÃ  Tabby váº«n bÃ¡o lá»—i mÃ u vÃ ng:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-error.jpg)

ThÃ¬ pháº£i enter token vÃ  server endpoint vÃ o VS Code:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config-token.jpg)

LÃ m sao Ä‘á»ƒ Chá»¯ Tabby hiá»‡n dáº¥u tick KHÃ”NG mÃ u vÃ ng lÃ  OK.
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config-ok.jpg)

VÃ o VS Code táº¡o 1 file Ä‘á»ƒ test: viáº¿t comment, xong cá»© tab theo lÃ  nÃ³ tá»± generate ra code. Ráº¥t Hay. VÃ  khÃ¡ nhanh, nhanh Ä‘áº¿n má»©c lÃ m mÃ¬nh báº¥t ngá»:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-demo.jpg)

## 10.3. Install Tabby binary file trÃªn Linux Ubuntu 22.04 VM

Tuy nhiÃªn binary thÃ¬ váº«n sáº½ bá»‹ lá»—i, cÃ³ láº½ bá»‹ tabby chÆ°a support arm64 ?:

```s
$ ./tabby serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct
-bash: ./tabby: cannot execute binary file: Exec format error
```

## 10.4. Install Tabby trÃªn Modal.com

Äá»ƒ táº¡o account modal.com, báº¡n cáº§n link nÃ³ vá»›i Github (mÃ¬nh táº¡o riÃªng 1 account github Ä‘á»ƒ link modal)

CÃ i Ä‘áº·t modal:

```s
$ python3.10 -m pip install modal
```

Káº¿t ná»‘i mÃ¡y local vá»›i Modal Ä‘á»ƒ deploy code lÃªn:

```s
$ python3.10 -m modal setup
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-setup.jpg)

Äáº¿n Ä‘Ã¢y modal Ä‘Æ°a 1 link Ä‘á»ƒ báº¡n truy cáº­p.

Sau khi má»Ÿ link trÃªn trÃ¬nh duyá»‡t Ä‘Ã£ login Github vÃ  Modal, báº¡n sáº½ cáº§n Authorize token API: (áº£nh)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-authorize.jpg)

Giao diá»‡n Modal sau khi Ä‘Ã£ Authorized:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-dashboard.jpg)

Giao diá»‡n Terminal sau khi Ä‘Ã£ Authorized:

```s
$ python3 -m modal setup
The `modal` command was not found on your path!
You may need to add it to your path or use `python -m modal` as a workaround.
See more information here:

https://modal.com/docs/guide/troubleshooting#command-not-found-errors

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Was not able to launch web browser
Please go to this URL manually and complete the flow:

https://modal.com/token-flow/tf-XXX

Web authentication finished successfully!
Token is connected to the GITHUB_USERNAME workspace.
Verifying token against https://api.modal.com
Token verified successfully!
Token written to /home/USER_NAME/.modal.toml in profile GITHUB_USERNAME.
```

LÃ m theo guide: https://tabby.tabbyml.com/docs/quick-start/installation/modal/

Copy code trong file: https://github.com/TabbyML/tabby/blob/main/website/docs/quick-start/installation/modal/app.py

Trong WSL táº¡o file `~/tabby-deployment/app.py`, sá»­a ná»™i dung chá»— nÃ y `allow_concurrent_inputs=200` Ä‘á»ƒ trÃ¡nh lá»—i "cá»© táº¡o container má»›i" vá» sau:
```py
@app.function(
    gpu=GPU_CONFIG,
    allow_concurrent_inputs=200,
    container_idle_timeout=120,
    timeout=360,
)
```

### Serve app tá»« local lÃªn Modal

```s
$ python3 -m modal serve app.py
âœ“ Initialized. View run at https://modal.com/apps/GITHUB_USERNAME/main/ap-oOhoNp6GE4ZEyLRG6nPoAj
Building image im-p2iVn8dvfr4jJHHA2vD53Q

...
Built image im-YWVKlo7mQ5FroC5LEIXGxt in 3.78s
âœ“ Created objects.
â”œâ”€â”€ ğŸ”¨ Created mount /home/USER_NAME/test-modal/app.py
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â””â”€â”€ ğŸ”¨ Created web function app_serve => https://GITHUB_USERNAME--tabby-server-app-serve-dev.modal.run
ï¸ï¸âš¡ï¸ Serving... hit Ctrl-C to stop!
â””â”€â”€ Watching /home/USER_NAME/test-modal.
â ´ Running (6 containers finished)... View app at https://modal.com/apps/GITHUB_USERNAME/main/ap-oOhoNp6GE4ZEyLRG6nPoAj
```

Váº«n giá»¯ terminal Ä‘ang cháº¡y, vÃ o link https://GITHUB_USERNAME--tabby-server-app-serve-dev.modal.run

Náº¿u báº¡n Ctrl+C á»Ÿ terminal thÃ¬ nÃ³ cÅ©ng sáº½ terminate cÃ¡i app Ä‘ang run trÃªn Modal.

### Deploy app tá»« local lÃªn Modal

```s
$ MODAL_FORCE_BUILD=1 python3.10 -m modal deploy app.py
Building image im-HDPO6oYXTb9cHnaVW5EgDJ
...
Image saved, took 1.55s

Built image im-M0269EbwJ9Hf0prQIHkSQP in 4.66s
âœ“ Created objects.
â”œâ”€â”€ ğŸ”¨ Created mount /home/USERNAME/test-modal/app.py
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â”œâ”€â”€ ğŸ”¨ Created function download_model.
â””â”€â”€ ğŸ”¨ Created web function app_serve => https://GITHUB_USERNAME--tabby-server-app-serve.modal.run
âœ“ App deployed in 170.844s! ğŸ‰

View Deployment: https://modal.com/apps/GITHUB_USERNAME/main/deployed/tabby-server
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-tabby-ui.jpg)

Giá» trÃªn VS Code config láº¡i cÃ¡c endpoint, token Ä‘á»ƒ Tabby trá» Ä‘áº¿n. 

Táº­n hÆ°á»Ÿng feature tabAutocomplete ráº¥t thÃº vá»‹ mÃ  Tabby Ä‘em láº¡i ğŸ˜˜ KhÃ¡ nhanh. KhÃ´ng khÃ¡c gÃ¬ cháº¡y local.

1 sá»‘ hÃ¬nh áº£nh trÃªn Modal dashboard:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps.jpg)

cÃ¡c thÃ´ng sá»‘ vÃ­ dá»¥ nhÆ° má»—i container nháº­n Concurrent input lÃ  200:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-details.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-files.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-func-calls.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-logs.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-secrets.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-storage.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps2.jpg)

tráº¡ng thÃ¡i idle báº¡n sáº½ ko bá»‹ tÃ­nh tiá»n:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-idle.jpg)

### Má»™t sá»‘ váº¥n Ä‘á» mÃ¬nh Ä‘ang gáº·p pháº£i [PENDING]

Persistant data container:

Náº¿u báº¡n ko dÃ¹ng VSCode 1 thá»i gian nÃ³ sáº½ tá»± Ä‘á»™ng Ä‘Æ°a Modal container Tabby vÃ o tráº¡ng thÃ¡i `idle`.

Báº¡n quay láº¡i VS Code rá»“i gÃµ 1 cÃ¡i gÃ¬ Ä‘Ã³, sáº½ trigger request Ä‘áº¿n Modal container Tabby vÃ  launch 1 container má»›i.

NhÆ°ng container nÃ y Ko cÃ³ data gÃ¬ cá»§a báº¡n. Giá»‘ng kiá»ƒu ko Ä‘Æ°á»£c mount volume váº­y.

Báº¡n sáº½ láº¡i pháº£i vÃ o link Modal Tabby, táº¡o láº¡i account admin, token. Rá»“i vÃ o config cá»§a VS Code extension Tabby - insert token má»›i.

Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y thÃ¬ mÃ¬nh cáº§n Ä‘á»c thÃªm tÃ i liá»‡u á»Ÿ Ä‘Ã¢y:

https://tabby.tabbyml.com/docs/administration/backup/

https://modal.com/docs/guide/cloud-bucket-mounts -> mount bucket s3

https://modal.com/docs/guide/mounting -> upload cáº£ folder local lÃªn

https://modal.com/docs/reference/cli/container -> command lÃ m viá»‡c vá»›i modal container

https://modal.com/docs/guide/secrets#using-secrets -> get secret tá»« modal vá»

NhÆ°ng váº«n chÆ°a tÃ¬m Ä‘Æ°á»£c cÃ¡ch Ä‘á»ƒ persistent data. ÄÃ£ thá»­ cÃ¡c hÆ°á»›ng Ä‘i sau:

- mount `/data/ee` vÃ o s3 nhÆ°ng sáº½ bá»‹ lá»—i nÃ y:

```s
â      3.200 s	Starting...
The application panicked (crashed).
Message:  Must be able to initialize db: migration 35 was previously applied but is missing in the resolved migrations
Location: /root/workspace/ee/tabby-webserver/src/webserver.rs:53
```

- ko dÃ¹ng mount mÃ  upload sáºµn 1 file `db.sqlite` lÃªn s3, trong code `app.py` thÃ¬ download file Ä‘Ã³ vá» folder `/data/ee`. NhÆ°ng sáº½ váº«n ko login Ä‘Æ°á»£c vá»›i account Ä‘Ã£ cÃ³ trong `db.sqlite`. Ko hiá»ƒu vÃ¬ sao.

- mÃ¬nh nghÄ© lÃ  do file `db.sqlite` á»Ÿ mÃ¡y local ko tÆ°Æ¡ng thÃ­ch vá»›i báº£n trÃªn modal nÃªn thá»­ cÃ¡ch táº¡o riÃªng 1 file `upload-db.py` Ä‘á»ƒ sau khi app Ä‘Ã£ cháº¡y thÃ¬ exec vÃ o container upload `db.sqlite` lÃªn s3 nhÆ° nÃ y:

    ```s
    ~/tabby-modal-deploy$ python3.10 -m modal container list
                                            Active Containers
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
    â”ƒ Container ID                  â”ƒ App ID                    â”ƒ App Name     â”ƒ Start Time           â”ƒ
    â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
    â”‚ ta-01J5JT8BEQJSRSPVK717HJA1T9 â”‚ ap-4GDFNbZ0vhsI8a3odHpFWb â”‚ tabby-server â”‚ 2024-08-18 20:21 +07 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 ls /root
    tabby-modal-deploy

    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 ls /root/tabby-modal-deploy
    __pycache__  app.py  app.py-bk2  app.py.bk  upload-db.py

    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 python /root/tabby-modal-deploy/upload
    -db.py
    Uploaded /data/ee/db.sqlite to s3://S3_BUCKET_NAME/hoangmnsd/ee/db.sqlite
    ```

  Sau Ä‘Ã³ deploy láº¡i app, trong app sáº½ download file `db.sqlite` chÃ­nh nÃ³ vá»«a upload lÃªn s3. 
  NhÆ°ng káº¿t quáº£ váº«n bá»‹ lá»—i ko thá»ƒ login.

Code `app.py` hiá»‡n Ä‘ang nhÆ° nÃ y náº¿u sau nÃ y mÃ¬nh muá»‘n quay láº¡i lÃ m tiáº¿p:

```py
"""Usage:
modal serve app.py

To force a rebuild by pulling the latest image tag, use:
MODAL_FORCE_BUILD=1 modal serve app.py
"""

import os
from modal import Image, App, asgi_app, gpu, Volume, Secret, CloudBucketMount

IMAGE_NAME = "tabbyml/tabby"
MODEL_ID = "TabbyML/StarCoder-1B"
CHAT_MODEL_ID = "TabbyML/Qwen2-1.5B-Instruct"
EMBEDDING_MODEL_ID = "TabbyML/Nomic-Embed-Text"
GPU_CONFIG = gpu.T4()

TABBY_BIN = "/opt/tabby/bin/tabby"

s3_bucket_name = "tabby-modal"  # Bucket name not ARN.
prefix_ee = 'hoangmnsd/ee/'

def download_model(model_id: str):
    import subprocess

    subprocess.run(
        [
            TABBY_BIN,
            "download",
            "--model",
            model_id,
        ]
    )

def download_file_from_s3(bucket_name: str, object_key: str, file_dir: str, file_name: str):
    import boto3
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"], # these env get from Secret "tabbymodalsyncs3" on Modal
        aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"], # these env get from Secret "tabbymodalsyncs3" on Modal
        region_name=os.environ["AWS_REGION"], # these env get from Secret "tabbymodalsyncs3" on Modal
    )
    local_file_path = file_dir + file_name
    s3.download_file(bucket_name, object_key, local_file_path)
    print(f"Downloaded s3://{bucket_name}/{object_key} to {local_file_path}")

def upload_file_to_s3(bucket_name: str, object_key: str, file_dir: str, file_name: str):
    import boto3
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"], # these env get from Secret "tabbymodalsyncs3" on Modal
        aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"], # these env get from Secret "tabbymodalsyncs3" on Modal
        region_name=os.environ["AWS_REGION"], # these env get from Secret "tabbymodalsyncs3" on Modal
    )
    local_file_path = file_dir + file_name
    s3.upload_file(local_file_path, bucket_name, object_key)
    print(f"Uploaded {local_file_path} to s3://{bucket_name}/{object_key}")

def download_s3():
    specific_file_key = 'hoangmnsd/ee/db.sqlite'
    downloaded_file_name = 'db.sqlite'
    downloaded_file_dir = '/data/ee/'
    download_file_from_s3(s3_bucket_name, specific_file_key, downloaded_file_dir, downloaded_file_name)

def upload_s3():
    specific_file_key = 'hoangmnsd/ee/db.sqlite'
    local_file_name = 'db.sqlite'
    local_file_dir = '/data/ee/'
    upload_file_to_s3(s3_bucket_name, specific_file_key, local_file_dir, local_file_name)

image = (
    Image.from_registry(
        IMAGE_NAME,
        add_python="3.11",
    )
    .dockerfile_commands("ENTRYPOINT []")
    .run_function(download_model, kwargs={"model_id": EMBEDDING_MODEL_ID})
    .run_function(download_model, kwargs={"model_id": CHAT_MODEL_ID})
    .run_function(download_model, kwargs={"model_id": MODEL_ID})
    .pip_install("asgi-proxy-lib")
    .pip_install("boto3")
)

app = App("tabby-server", image=image)

@app.function(
    gpu=GPU_CONFIG,
    allow_concurrent_inputs=200,
    container_idle_timeout=120,
    timeout=360,
    secrets=[Secret.from_name("tabbymodalsyncs3")], # you need to create Secret "tabbymodalsyncs3" on Modal first
)

@asgi_app()
def app_serve():
    import socket
    import subprocess
    import time
    from asgi_proxy import asgi_proxy

    launcher = subprocess.Popen(
        [
            TABBY_BIN,
            "serve",
            "--model",
            MODEL_ID,
            "--chat-model",
            CHAT_MODEL_ID,
            "--port",
            "8000",
            "--device",
            "cuda",
            "--parallelism",
            "1",
        ]
    )

    # Poll until webserver at 127.0.0.1:8000 accepts connections before running inputs.
    def tabby_ready():
        try:
            socket.create_connection(("127.0.0.1", 8000), timeout=1).close()
            return True
        except (socket.timeout, ConnectionRefusedError):
            # Check if launcher webserving process has exited.
            # If so, a connection can never be made.
            retcode = launcher.poll()
            if retcode is not None:
                raise RuntimeError(f"launcher exited unexpectedly with code {retcode}")
            return False

    while not tabby_ready():
        time.sleep(1.0)

    # Wait briefly to allow the "serve" command to initialize
    time.sleep(60)  # Adjust the sleep duration as necessary for your use case
    print("--debug1")
    subprocess.run(["ls", "/data/ee/"])
    # subprocess.run(["mkdir", "-p", "/data/ee"]) # prepare ee dir to prevent error https://stackoverflow.com/a/73193346/9922066
    print("--debug2")
    download_s3()
    subprocess.run(["ls", "/data/ee/"])
    # upload_s3()
    print("Tabby server ready!")
    return asgi_proxy("http://localhost:8000")
```


## 10.5. Install Tabby trÃªn Huggingface Space

HF cÃ³ nhiá»u loáº¡i Plan:
- Pro: account 9$/month
- Space: gáº§n nhÆ° lÃ  Serverless, set inactive time Ä‘á»ƒ container stop náº¿u ko cÃ³ traffic. Free 2 cpu / 16G RAM. Pricing: https://huggingface.co/pricing#spaces
- Inference endpoints: gáº§n nhÆ° Serverless. Pricing: https://huggingface.co/pricing#endpoints

Hiá»‡n táº¡i Ä‘á»ƒ dÃ¹ng Ä‘Æ°á»£c HF Space cáº§n add credit card. HuggingFace hiá»‡n váº«n chÆ°a cho phÃ©p mua pre-paid Credit báº±ng tháº». (Khoáº£n nÃ y kÃ©m OpenAI)

Guide install Tabby:
- https://tabby.tabbyml.com/docs/quick-start/installation/hugging-face/
- https://huggingface.co/docs/hub/spaces-sdks-docker-tabby

Viá»‡c deploy Ä‘Æ¡n giáº£n lÃ  do Tabby Ä‘Ã£ cÃ³ sáºµn 1 space template vÃ  ta áº¥n vÃ o link lÃ  nÃ³ tá»± duplicate space Ä‘Ã³ luÃ´n. Cháº£ pháº£i code gÃ¬

áº¤n vÃ o link: https://huggingface.co/spaces/TabbyML/tabby-template-space?duplicate=true

á» Ä‘Ã¢y mÃ¬nh cá»‘ tÃ¬nh chá»n cÃ¡c option FREE ko tÃ­nh tiá»n:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-1.jpg)

Chá» container log deploy xong:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-2.jpg)

Náº¿u tháº¥y lá»—i nhiá»u nhÆ° nÃ y, kháº£ nÄƒng nguyÃªn nhÃ¢n do mÃ¬nh chá»n Hardware CPU ko cÃ³ GPU:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-containerlog.jpg)

Thá»­ sá»­a láº¡i Dockerfile rá»“i commit lÃªn main:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-edit-Dockerfile.jpg)

Sá»­a xong, commit xong thÃ¬ nhá»› Restart Space Ä‘á»ƒ run láº¡i container:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-restart.jpg)

Sau 1 há»“i váº«n ko fix Ä‘Æ°á»£c lá»—i nÃ y. Chá»‹u. CÃ³ láº½ cáº§n chá» Tabby há» release Docker images fix Ä‘Æ°á»£c háº¿t lá»—i.

Náº¿u muá»‘n báº¡n cÃ³ thá»ƒ thá»­ deploy báº£n dÃ¹ng GPU (máº¥t tiá»n) Ä‘á»ƒ thá»­ (Cháº¯c sáº½ ko cÃ³ lá»—i nhÆ° trÃªn)

## 10.6. Install Tabby trÃªn BentoCloud

Khi Ä‘Äƒng kÃ½ BentoCloud há» cho trÆ°á»›c 10$ credit. KhÃ´ng hÃ o phÃ³ng nhÆ° Modal cho 30$.

https://tabby.tabbyml.com/docs/quick-start/installation/bentoml/

Xem guide cá»§a Tabby tháº¥y nhiá»u file hÆ¡n Modal.

Láº¡i cÃ²n sync file tá»« R2 Cloudflare ná»¯a nÃªn pháº£i setup nhiá»u thá»© quÃ¡, mÃ¬nh náº£n ko muá»‘n lÃ m.

Dá»c ká»¹ thÃ¬ Ã½ tÆ°á»Ÿng Ä‘á»‘i vá»›i R2 Cloudflare lÃ  Ä‘á»ƒ khi shutdown thÃ¬ upload `.tabby` database lÃªn R2. Khi deploy thÃ¬ download vá» Ä‘á»ƒ persist database. (**LÃ  Ä‘iá»u mÃ  trong Guideline Tabby vá»›i Modal chÆ°a lÃ m**)

# 11. Tabnine

# 12. Blackbox

# 13. Codeium

# REFERENCES

https://dev.to/lunary/7-open-source-ai-projects-to-code-faster-in-2023-2306

Tabby recommend cáº¥u hÃ¬nh pháº§n cá»©ng (GPU) cho cÃ¡c model á»Ÿ Ä‘Ã¢y: https://tabby.tabbyml.com/docs/models/

Tabby xáº¿p háº¡ng cÃ¡c model á»Ÿ Ä‘Ã¢y: https://leaderboard.tabbyml.com/

1 sá»‘ vÃ­ dá»¥ Ä‘á»ƒ deploy cÃ¡c app cá»§a báº¡n lÃªn Modal: https://modal.com/docs/examples/web-scraper
