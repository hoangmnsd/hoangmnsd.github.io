---
title: "Setting up AI coding assistant"
date: 2024-07-26T21:56:40+07:00
draft: false
authors: ["hoangmnsd"]
categories: [Tech-Tutorials]
tags: [Extension,AI,Agent,LLM]
comments: true
toc: true
# below props are for the404blog theme
authorImg: "https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/hoangmsnd-avatar001.jpg"
description: "B√†i n√†y gi·ªõi thi·ªáu v·ªÅ 1 tool AI coding assistant r·∫•t th√∫ v·ªã..."
---

T∆∞∆°ng lai c√¥ng vi·ªác c·ªßa Developer s·∫Ω "nh√†n" ƒëi r·∫•t nhi·ªÅu.. v√† c≈©ng **c·∫°nh tranh** h∆°n r·∫•t nhi·ªÅu v·ªõi s·ª± xu·∫•t hi·ªán c·ªßa c√°c c√¥ng c·ª• AI Coding assistant/agent nh∆∞ th·∫ø n√†y...

B·∫°n ho√†n to√†n c√≥ th·ªÉ "ra chu·ªìng g√†" n·∫øu ko xu√¥i m√¨nh theo d√≤ng ch·∫£y c·ªßa th·ªùi ƒë·∫°i.

# 1. Mentat (d·ª´ng update t·ª´ th√°ng 4/2024)

## 1.1. Overview

M√¨nh ƒë∆∞·ª£c bi·∫øt ƒë·∫øn [mentat](https://github.com/AbanteAI/mentat) qua 1 repo n√†o ƒë√≥ v·ªÅ ChatGPT.

Mentat open source v√† b·∫°n s·∫Ω s·ª≠ d·ª•ng OpenAI API key ƒë·ªÉ cung c·∫•p cho n√≥.

B·∫°n cho n√≥ ƒë·ªçc 1 s·ªë file code c·ªßa b·∫°n l√† input ƒë·∫ßu v√†o, sau ƒë√≥ b·∫°n chat v·ªõi n√≥ tr√™n terminal, n√≥ s·∫Ω gi√∫p b·∫°n code lu√¥n üòÄ

## 1.2. Setup Mentat tr√™n Windows + GitBash + VS Code

Download python3.11 (tr√™n 3.10 l√† OK) v·ªÅ

https://www.python.org/downloads/release/python-3119/

C√†i ƒë·∫∑t (Khi c√†i th√¨ nh·ªõ tick ch·ªçn v√†o ch·ªó add/export to PATH env variable)

Verify xem `python.exe` c√≥ t·ªìn t·∫°i trong folder n√†y ko:

`C:\Users\<USER_NAME_C·ª¶A_B·∫†N>\AppData\Local\Programs\Python\Python311\python.exe`

M·ªü Gitbash, chuy·ªÉn version m·∫∑c ƒë·ªãnh sang python3.11 m·ªõi download v·ªÅ:

```sh
cd ~

nano .bashrc

# S·ª≠a file th√™m d√≤ng sau:
alias python='winpty "C:\Users\<USER_NAME_C·ª¶A_B·∫†N>\AppData\Local\Programs\Python\Python311\python.exe"'
# ƒê√≥ng file save l·∫°i

source .bashrc

# Check l·∫°i xem ƒë√∫ng chuy·ªÉn sang version m·ªõi ch∆∞a
python --version
```

Trong Gitbash, install pip, ko c√≥ l·ªói g√¨ l√† ok:

```sh
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py

python get-pip.py
```

Trong Gitbash activate venv, install mentat:

```sh
# (optional) B·∫°n c√≥ th·ªÉ create venv ho·∫∑c ko. M√¨nh suggest l√† ko c·∫ßn
# V√¨ khi t·∫°o .venv, b·∫°n c·∫ßn t·∫°o th√™m gitignore ƒë·ªÉ mentat ko d√πng folder .venv l√†m input ƒë·∫ßu v√†o. Nh∆∞ v·∫≠y s·∫Ω t·ªën nhi·ªÅu ti·ªÅn c·ªßa OpenAI key.
python -m venv .venv
source .venv/Scripts/activate

python -m pip install git+https://github.com/AbanteAI/mentat.git
```

Hi·ªán khi s·ª≠ d·ª•ng mentat m√¨nh ƒëang b·ªã l·ªói:

```
USER_NAME_C·ª¶A_B·∫†N@AAA-BBB MINGW64 C:/Users/USER_NAME_C·ª¶A_B·∫†N/AppData/Local/Programs/Microsoft VS Code (master)
$ mentat
bash: mentat: command not found
```

Th√¨ h√£y th√™m command sau ƒë·ªÉ mentat c√≥ trong env PATH:

```s
export PATH=$PATH:/c/Users/<USER_NAME_C·ª¶A_B·∫†N>/AppData/Local/Programs/Python/Python311/Scripts
```

Gi·ªù add OpenAPI key v√†o ƒë·ªÉ mentat s·ª≠ d·ª•ng:

```sh
export OPENAI_API_KEY=<your key here>
```

Gi·ªù g√µ mentat t√™n c√°c file input ƒë·∫ßu v√†o cho n√≥ ƒë·ªçc. Sau ƒë√≥ chat v·ªõi n√≥ th√¥i.

B·∫°n c√≥ th·ªÉ ƒë∆∞a c·∫£ folder cho n√≥ ƒë·ªçc c≈©ng ƒë∆∞·ª£c. Nh∆∞ng ƒëi·ªÅu ƒë√≥ ƒë·ªìng nghƒ©a v·ªõi vi·ªác b·∫°n ko qu·∫£n l√Ω s·ªë l∆∞·ª£ng input ƒë·∫ßu v√†o cho mentat. Khi·∫øn key c·ªßa b·∫°n c√≥ th·ªÉ h·∫øt ti·ªÅn nhanh h∆°n.

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-assist-mentat-01.jpg)

Hi·ªán t·∫°i c√≥ 1 v·∫•n ƒë·ªÅ nh·ªè, l√† mentat ch·ªâ c√≥ th·ªÉ s·ª≠a code 1 file t·∫°i 1 th·ªùi ƒëi·ªÉm. N·∫øu b·∫°n y√™u c·∫ßu n√≥ s·ª≠a code 2 file, n√≥ in ra c√¢u tr·∫£ l·ªùi nh∆∞ng khi b·∫°n ·∫•n `Apply change` n√≥ s·∫Ω ch·ªâ s·ª≠a 1 file.

V√† 1 v·∫•n ƒë·ªÅ to, l√† Mentat ko support/k√©m support c√°c OpenAI model kh√°c (gpt-4o-mini/gpt-4o) v√† Opensource Model nh∆∞ Ollama.

# 2. Github Copilot

T∆∞∆°ng t·ª± nh∆∞ Mentat nh∆∞ng b·∫°n tr·∫£ ti·ªÅn tr·ª±c ti·∫øp cho Github. 10$ per month. D√πng th·ª≠ 30 days.

B·∫°n vi·∫øt comment trong code v√† ·∫•n Ctr+I ƒë·ªÉ h·ªèi n√≥ tr·ª±c ti·∫øp trong file code.

{{< youtube Fi3AJZZregI >}}

https://www.youtube.com/watch?v=Fi3AJZZregI&list=PLj6YeMhvp2S5_hvBl2SE-7YCHYlLQ0bPt&ab_channel=VisualStudioCode

https://www.youtube.com/watch?v=aGbfU4GiI9s&ab_channel=Ph%E1%BA%A1mHuyHo%C3%A0ng


# 3. Amazon Q Developer

https://aws.amazon.com/q/developer/pricing/

C√≥ tier Free gi·ªõi h·∫°n: limit 50 interactions per month

Video gi·ªõi thi·ªáu: https://www.youtube.com/watch?v=i0zQpJPfSdU&ab_channel=AWSDevelopers

{{< youtube i0zQpJPfSdU >}}


# 4. ContinueDev (Recommend)

## 4.1. Overview

So v·ªõi Mentat th√¨ m√¨nh th·∫•y c√°i n√†y t·ªët h∆°n nhi·ªÅu, Link github: https://github.com/continuedev/continue

Quan tr·ªçng nh·∫•t l√† n√≥ x·ª≠ l√Ω ƒë∆∞·ª£c v·∫•n ƒë·ªÅ c·ªßa Mentat l√† ko d√πng ƒë∆∞·ª£c c√°c OpenAI model kh√°c nh∆∞ (gpt-4o, gpt-4o-mini), sau ƒë√≥ l√† c√≥ th·ªÉ d√πng c√°c Ollama model n·ªØa.

## 4.2. Setup ContinueDev v·ªõi nhi·ªÅu endpoint kh√°c nhau

Sau khi ƒë√£ install VS Code extension.

S·ª≠a file `C:\Users\YOUR_USER_NAME\.continue\config.json` ƒë·ªÉ k·∫øt n·ªëi v·ªõi OpenAI gpt-4o-mini:
```json
{
  "models": [
    {
      "title": "GPT-4o-mini",
      "provider": "openai",
      "model": "gpt-4o-mini",
      "apiKey": "sk-proj-XXX"
    }
  ]
```

S·ª≠a file `C:\Users\YOUR_USER_NAME\.continue\config.json` ƒë·ªÉ k·∫øt n·ªëi v·ªõi Ollama c·ªßa c√° nh√¢n (k·∫øt h·ª£p Ollama v·ªõi https://github.com/ParisNeo/ollama_proxy_server ƒë·ªÉ c√≥ apiKey):
```json
{
  "models": [
    {
      "title": "llama3.1",
      "provider": "ollama",
      "model": "llama3.1",
      "apiKey": "user1:ABC",
      "apiBase": "https://ollamaproxy.[YOUR_DOMAIN].duckdns.org/"
    }
  ],
```

Ri√™ng Perplexity th√¨ h·ªç ko expose h·∫øt api n√™n s·∫Ω b·ªã l·ªói. N·∫øu config tr·ªè ƒë·∫øn Perplexity s·∫Ω b·ªã l·ªói do perplexity ch·ªâ m·ªü api cho `/chat/completions` th√¥i:
```json
{
  "models": [
    {
      "title": "llama-3.1-8b-instruct",
      "provider": "openai",
      "model": "llama-3.1-8b-instruct",
      "apiKey": "pplx-xxx",
      "apiBase": "https://api.perplexity.ai"
    }
  ],
```

L·ªói hi·ªán t·∫°i khi k·∫øt n·ªëi Perplexity:
```
Error streaming diff: Error: HTTP 400 Bad Request from https://api.perplexity.ai/completions {"error":{"message":"The model should only be queried with the /chat/completions endpoint.","type":"invalid_model","code":400}}
```

C√≥ th·ªÉ d√πng ctrl+L ƒë·ªÉ chat v·ªõi Perplexity, nh∆∞ng ko d√πng ƒë∆∞·ª£c Ctrl+I v√¨ n√≥ ƒëang tr·ªè ƒë·∫øn path kh√°c.

N·∫øu s·ª≠a `apiBase=https://api.perplexity.ai/chat/` ƒë·ªÉ d√πng th·ª≠ Ctrl+I th√¨ v·∫´n l·ªói:
```
Error streaming diff: Error: HTTP 400 Bad Request from https://api.perplexity.ai/chat/completions {"error":{"message":"[\"At body -> messages: Field required\"]","type":"bad_request","code":400}}
```

T√∫m l·∫°i, hi·ªán t·∫°i ch·ªâ c√≥ th·ªÉ d√πng ContinueDev V·ªõi OpenAI (c√°c model) v√† Ollama (ph·∫£i ƒëi k√®m ollama_proxy_server ƒë·ªÉ c√≥ apikey)

## 4.3. Th·ª≠ tabAutocompleteModel d√πng model Ollama starcoder:1b

Ch·ªó file `C:\Users\YOUR_USER_NAME\.continue\config.json`, `tabAutocompleteModel` n√™n d√πng theo recommend sau:
https://docs.continue.dev/features/tab-autocomplete

Hi·ªán t·∫°i th√¨ m√¨nh d√πng ContnueDev v·ªõi ch·ª©c nƒÉng Ctrl+I v√† Ctrl+L th√¥i, ƒëang disable ch·ª©c nƒÉng `tabAutocomplete` n√†y v√¨ nghƒ© n√≥ s·∫Ω spam OpenAI API l√†m t·ªën ti·ªÅn.

Sau khi s·ª≠ d·ª•ng Tabby, m√¨nh th·∫•y ch·ª©c nƒÉng r·∫•t hay c·ªßa Tabby l√† Autocomplete r·∫•t nhanh. M√¨nh nghƒ© c√≥ th·ªÉ do n√≥ d√πng model `starcoder:1b` nh·∫π ~800Mb n√™n nhanh v·∫≠y/

N√™n m√¨nh c√≥ √Ω t∆∞·ªüng l√†: Deploy model `starcoder:1b` tr√™n Ollama r·ªìi cho ContinueDev s·ª≠ d·ª•ng th·ª≠. S·ª≠a file `C:\Users\YOUR_USER_NAME\.continue\config.json`:

```json
"tabAutocompleteModel": [
    {
      "title": "starcoder:1b",
      "provider": "ollama",
      "model": "starcoder:1b",
      "apiBase": "https://YOUR_OLLAMA_SERVER.org/",
      "apiKey": "user:pass"
    }
  ],
```

Nh∆∞ng k·∫øt qu·∫£ l√† Ollama tr√™n server c·ªßa m√¨nh ph·∫£i x·ª≠ l√Ω request li√™n t·ª•c b·ªã 100% CPU ü§£ tab auto r·∫•t ch·∫≠m...

Nh∆∞ v·∫≠y l√† ContinueDev ƒë√†nh disable ch·ª©c nƒÉng tabAutocomplete th√¥i. üò™

ƒê·ªçc th√™m v·ªÅ config: https://docs.continue.dev/setup/configuration

# 5. GPT Pilot

https://github.com/Pythagora-io/gpt-pilot

Demo c√≥ v·∫ª r·∫•t hay nh∆∞ng ko th·∫•y d√πng ƒë∆∞·ª£c OpenAI API key, c·ª© b·∫Øt Subscribe Pythgora Pro m·ªõi cho chat.

C√≥ docs v·ªÅ d√πng v·ªõi my own OpenAI key: https://github.com/Pythagora-io/gpt-pilot/wiki/Using-Pythagora-with-your-own-OpenAI-key

Nh∆∞ng d√π config ƒë√∫ng v·∫´n ko d√πng ƒë∆∞·ª£c. M√¨nh ch·ªãu b·ªè qua lu√¥n.

Ngo√†i ra c√≤n b·∫Øt login account pythagora n√™n c√†ng √°c c·∫£m.

# 6. ChatDev

https://github.com/OpenBMB/ChatDev

√Ω t∆∞·ªüng kh√° hay khi t·∫°o 1 c√¥ng ty thu nh·ªè, m·ªói model ƒë·∫£m nhi·ªám 1 role nh∆∞ CEO, CTO, programmer, tester, designer. Ch√∫ng s·∫Ω t·ª± n√≥i chuy·ªán v·ªõi nhau ƒë·ªÉ t·∫°o ra s·∫£n ph·∫©m ü§£

C√°i n√†y th·ª±c s·ª± l√†m m√¨nh ·∫•n t∆∞·ª£ng v·ªÅ c√°ch h·ªç d√πng ChatGPT ƒë·ªÉ t·∫°o ra s·∫£n ph·∫©m

## 6.1. Run on WSL Ubuntu 22.04

```s
git clone https://github.com/OpenBMB/ChatDev.git

python3.10 -m venv venv

source venv/bin/activate

cd ChatDev/
pip3 install -r requirements.txt
export OPENAI_API_KEY="your_OpenAI_API_key"

python3 run.py --task "create a flabby bird game web application runing in javascript" --name "FlabbyBirdHoangmnsd"

python3 run.py --task "using python, create a web application to chat with chatGPT using exist OPENAI API Key" --name "ChatWithGPT"
```

Ch·ªâ c·∫ßn ng·∫Øn g·ªçn nh∆∞ v·∫≠y th√¥i, ChatDev s·∫Ω chia th√†nh c√°c role nh∆∞ CEO, CTO, programmer, tester, blabla ƒë·ªÉ t·ª± th·∫£o lu·∫≠n v·ªõi nhau v√† ƒë∆∞a ra c√¢u tr·∫£ l·ªùi cho b·∫°n.

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished.jpg)

## 6.2 Run application t·∫°o b·ªüi ChatDev

Code s·∫Ω n·∫±m trong folder n√†y `WareHouse`: 

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product.jpg)

Gi·ªù m√¨nh l√†m theo h∆∞·ªõng d·∫´n trong file `WareHouse/<PROJECT_NAME>/manual.md`

N·∫øu g·∫∑p l·ªói ki·ªÉu n√†y:

```s
$ python3.10 main.py
 * Serving Flask app 'main' (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
Permission denied
```

Nguy√™n nh√¢n l√† do M√°y m√¨nh ko ƒë∆∞·ª£c ph√©p run tr√™n port 5000, H√£y s·ª≠a code th√†nh Flask ch·∫°y tr√™n port 8001 ch·∫≥ng h·∫°n:

```py
if __name__ == '__main__':
    app.run(host="0.0.0.0", port=8001, debug=True)
```

N·∫øu g·∫∑p l·ªói ki·ªÉu n√†y:

```s
jinja2.exceptions.TemplateNotFound: index.html
```

C√≥ nghƒ©a l√† Flask ƒëang t√¨m html file trong folder `templates/index.html`. H√£y t·∫°o folder v√† cho file v√†o ƒë√≥.

App ƒëang run ·ªü port 8001:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run1.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run2.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-product-run3.jpg)

Trong qu√° tr√¨nh run app c·ªßa ChatDev t·∫°o ra, b·∫°n c√≥ th·ªÉ g·∫∑p nhi·ªÅu l·ªói kh√°c nhau (2 l·ªói nh∆∞ m√¨nh ƒë√£ li·ªát k√™ b√™n tr√™n). V√† 1 s·ªë l·ªói li√™n quan ƒë·∫øn code ki·ªÉu API ko c√≤n support nh∆∞ng ChatDev v·∫´n d√πng. (https://stackoverflow.com/a/76027573). 

ƒêi·ªÅu n√†y c√≥ th·ªÉ th·∫•y l√† do ChatDev v·∫´n ƒëang d√πng nh∆∞ng ki·∫øn th·ª©c c≈©, ch∆∞a c·∫≠p nh·∫≠t l·∫Øm. 

Tuy nhi√™n √Ω t∆∞·ªüng l√† r·∫•t t√°o b·∫°o. 
Trong ƒëi·ªÅu ki·ªán ho√†n h·∫£o (Ko c√≥ ki·∫øn th·ª©c n√†o c·ªßa ChatDev d√πng b·ªã outdate, ko c√≥ l·ªói m√¥i tr∆∞·ªùng t·ª´ ph√≠a b·∫°n) B·∫°n ho√†n to√†n c√≥ th·ªÉ t·ªën d∆∞·ªõi 1$ cho 1 ph·∫ßn m·ªÅm. R√∫t ng·∫Øn qu√° tr√¨nh t·∫°o ph·∫ßn m·ªÅm ƒë√°ng k·ªÉ.

## 6.3. Review qu√° tr√¨nh ChatDev t·∫°o ra s·∫£n ph·∫©m

D√πng command sau;

```py
python ChatDev/visualizer/app.py
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chatvisualizer.jpg)

b·∫°n upload file .log trong foldedr c·ªßa project l√™n l√† th·∫•y:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay.jpg)

B·∫°n s·∫Ω th·∫•y c√°c con bot chat v·ªõi nhau nh∆∞ th·∫ø n√†o ƒë·ªÉ t·∫°o ra s·∫£n ph·∫©m

CEO chat g√¨, CPO (Product Owner) r·ªìi CTO chat ntn, Programmer, Code Reviewer, Counselor, Designer....

1 cu·ªôc n√≥i chuy·ªán ch√¢n th·ª±c ü§£ü§£

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay-2.jpg)

Code Reviewer t√¨m ra l·ªói:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/ai-coding-agent-chatdev-when-finished-chat-replay-3.jpg)

N·∫øu b·∫°n mu·ªën ƒë·ªçc k·ªπ h∆°n c√°c option th√¨ ƒë·ªçc ·ªü ƒë√¢y: https://github.com/OpenBMB/ChatDev/blob/main/wiki.md

```
usage: run.py [-h] [--config CONFIG] [--org ORG] [--task TASK] [--name NAME] [--model MODEL]

argparse

optional arguments:
  -h, --help       show this help message and exit
  --config CONFIG  Name of config, which is used to load configuration under CompanyConfig/; Please see CompanyConfig Section below
  --org ORG        Name of organization, your software will be generated in WareHouse/name_org_timestamp
  --task TASK      Prompt of your idea
  --name NAME      Name of software, your software will be generated in WareHouse/name_org_timestamp
  --model MODEL    GPT Model, choose from {'GPT_3_5_TURBO','GPT_4','GPT_4_32K'}
```

Hi·ªán ChatDev ch∆∞a h·ªó tr·ª£ gpt-4o gpt-4o-mini. Ch·ªçn GPT_4 s·∫Ω kh√° ƒë·∫Øt khi 1 project nh·ªè c≈©ng m·∫•t h∆°n 1$

ƒê·ªëi v·ªõi ChatDev do nhu c·∫ßu s·ª≠ d·ª•ng v√† view file nhi·ªÅu n√™n m√¨nh nghƒ© n√™n d√πng ChatDev run b·∫±ng GitBash. Ko n√™n run b·∫±ng WSL. 

## 6.4. Troubleshoot

Trong qu√° tr√¨nh install ChatDev, Hi·ªán c√≥ th·ªÉ b·∫°n s·∫Ω g·∫∑p l·ªói ki·ªÉu n√†y: 
```s
TypeError: init() got an unexpected keyword argument 'refusal'
```
C√°ch fix workaround t·∫°m th·ªùi: https://github.com/OpenBMB/ChatDev/issues/413#issuecomment-2283267043

# 7. Localpilot

https://github.com/danielgross/localpilot/issues/12

Proxy t·ª´ Github Copilot sang c√°c local model, Nh∆∞ng v·∫´n b·∫Øt login Github m√¨nh th·∫•y h∆°i nguy hi·ªÉm.

# 8. Lunary

https://github.com/lunary-ai/lunary

√Ω t∆∞·ªõng kh√° hay, monitor s·ªë l∆∞·ª£ng request token, cost, ƒë·ªô tr·ªÖ, log, c·ªßa c√°c LLM models.

Ko h·∫≥n l√† AI Coding Agent, m√† gi·ªëng nh∆∞ 1 tool ƒë·ªÉ monitoring.

# 9. Swirl

https://github.com/swirlai/swirl-search

√Ω t∆∞·ªüng l√† D√πng ƒë·ªÉ t·∫°o 1 web ui cho search. T√†i li·ªáu s·∫Ω l√† Notes/docs/code c·ªßa c√° nh√¢n... gi·ªëng google, ms365, openai. nh∆∞ng d√πng ƒë·ªÉ search t√†i li·ªáu c·ªßa b·∫°n

Ko h·∫≥n l√† AI Coding Agent, m√† gi·ªëng nh∆∞ 1 tool search nh·ªâ?

# 10. Tabby

https://tabby.tabbyml.com/docs/quick-start/installation/docker-compose/

## 10.1. Overview

c≈©ng l√† ki·ªÉu AI Coding agent c·ªßa VS Code, run open source model locally.

∆Øu ƒëi·ªÉm:
- Ph·∫£n h·ªìi nhanh, m√¨nh c·∫£m th·∫•y kh√° b·∫•t ng·ªù v√¨ t·ªëc ƒë·ªô d√π ch·ªâ ch·∫°y CPU mode.
- Document kh√° clear.
- C√≥ support tr√™n nhi·ªÅu platform kh√°c nhau (AWS, SkyPilot, Huggingface Space, BentoCloud, Modal... c√≥ n√≥i r√µ).
- C√≥ support nhi·ªÅu ki·ªÉu install: Linux binary file, Docker container, Windows exe.
- C√≥ support nhi·ªÅu OS: Windows, WSL, Linux, Macos.
- C√≥ support c·∫£ GPU v√† CPU.

Nh∆∞·ª£c ƒëi·ªÉm:
- Docker arm64 ch∆∞a support https://github.com/TabbyML/tabby/issues/623.
- (? not sure ?) 
  ƒê·ªçc issue n√†y th·∫•y Tabby ch·ªâ t·ª± run model, ko c√≥ √Ω ƒë·ªãnh s·ª≠ d·ª•ng c√°c external endpoint nh∆∞ OpenAI, Ollama: https://github.com/TabbyML/tabby/issues/795.
  nh∆∞ng l·∫°i c√≥ docs n√†y n√≥i v·ªÅ OpenAI, Ollama https://tabby.tabbyml.com/docs/references/models-http-api/openai/ (M√¨nh l√†m theo th√¨ ko ƒëc)
- Hi·ªán m√¨nh install v·∫´n ƒëang b·ªã l·ªói b·∫£n docker WSL (CPU mode): https://github.com/TabbyML/tabby/discussions/2867

Hi·ªán minh ƒëang install b·∫£n binary file tr√™n WSL Ubuntu 22.04. Ch·∫°y kh√° nhanh.

## 10.2. Install Tabby binary file tr√™n Windows WSL ubuntu 22.04

theo guide https://tabby.tabbyml.com/docs/quick-start/installation/linux/#download-the-release

```sh
sudo apt-get install libgomp1
cd ~/test-tabby/
wget https://github.com/TabbyML/tabby/releases/download/nightly/tabby_x86_64-manylinux2014.zip
mkdir tabby-binary/
unzip -d tabby-binary/ tabby_x86_64-manylinux2014.zip

# direct to binary files

chmod +x tabby llama-server
# For CPU-only environments
./tabby serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct
```

log OK:
```
  As an open source project, we collect usage statistics to inform development priorities. For more
  information, read https://tabby.tabbyml.com/docs/configuration#usage-collection

  We will not see or any code in your development process.

  Welcome to Tabby!

  If you have any questions or would like to engage with the Tabby team, please join us on Slack
  (https://links.tabbyml.com/join-slack-terminal).



‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó
‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó  ‚ïö‚ñà‚ñà‚ïî‚ïù
   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë
   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù

üìÑ Version 0.16.0-dev.0
üöÄ Listening at http://0.0.0.0:8080



  JWT secret is not set

  Tabby server will generate a one-time (non-persisted) JWT secret for the current process.
  Please set the TABBY_WEBSERVER_JWT_TOKEN_SECRET environment variable for production usage.

```

R·ªìi tr√™n Window Powershell get WSL ip: `wsl hostname -I` ho·∫∑c `wsl hostname -i` v√≠ d·ª• l·∫•y ƒë∆∞·ª£c `172.27.45.193`

R·ªìi m·ªü Chrome s·∫Ω access ƒë∆∞·ª£c tabby qua port 8080: http://172.27.45.193:8080

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-sign-up-screen.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-sign-up-screen-2.jpg)

account: user/password

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-dashboard.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-dashboard-chat.jpg)

B·∫°n c√≥ th·ªÉ chat v·ªõi n√≥ lu√¥n. Tr·∫£ l·ªùi kh√° nhanh, c√≥ l·∫Ω v√¨ d√πng model `Qwen2-1.5B-Instruct`? Ch·ª© m√¨nh ch·∫°y Lmstudio chat v·ªõi n√≥ ch·∫≠m vl.

V√†o setting ƒë·ªÉ xem c√≥ r·∫•t nhi·ªÅu feature th√∫ v·ªã:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-system-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-joib-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-report-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-act-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-general-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-mem-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-subs-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-context-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-sso-info.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-mail-info.jpg)

Tr√™n VS Code install Tabby extension, r·ªìi v√†o ƒë√¢y update token v√† endpoint url:
`C:\Users\USER_NAME\.tabby-client\agent\config.toml`
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config.jpg)

D√π s·ª≠a ·ªü file `config.toml`, nh∆∞ng v√†o VS Code, nh√¨n g√≥c d∆∞·ªõi b√™n ph·∫£i v√† Tabby v·∫´n b√°o l·ªói m√†u v√†ng:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-error.jpg)

Th√¨ ph·∫£i enter token v√† server endpoint v√†o VS Code:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config-token.jpg)

L√†m sao ƒë·ªÉ Ch·ªØ Tabby hi·ªán d·∫•u tick KH√îNG m√†u v√†ng l√† OK.
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-config-ok.jpg)

V√†o VS Code t·∫°o 1 file ƒë·ªÉ test: vi·∫øt comment, xong c·ª© tab theo l√† n√≥ t·ª± generate ra code. R·∫•t Hay. V√† kh√° nhanh, nhanh ƒë·∫øn m·ª©c l√†m m√¨nh b·∫•t ng·ªù:
![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-setting-vs-code-demo.jpg)

## 10.3. Install Tabby binary file tr√™n Linux Ubuntu 22.04 VM

Tuy nhi√™n binary th√¨ v·∫´n s·∫Ω b·ªã l·ªói, c√≥ l·∫Ω b·ªã tabby ch∆∞a support arm64 ?:

```s
$ ./tabby serve --model StarCoder-1B --chat-model Qwen2-1.5B-Instruct
-bash: ./tabby: cannot execute binary file: Exec format error
```

## 10.4. Install Tabby tr√™n Modal.com

ƒê·ªÉ t·∫°o account modal.com, b·∫°n c·∫ßn link n√≥ v·ªõi Github (m√¨nh t·∫°o ri√™ng 1 account github ƒë·ªÉ link modal)

C√†i ƒë·∫∑t modal:

```s
$ python3.10 -m pip install modal
```

K·∫øt n·ªëi m√°y local v·ªõi Modal ƒë·ªÉ deploy code l√™n:

```s
$ python3.10 -m modal setup
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-setup.jpg)

ƒê·∫øn ƒë√¢y modal ƒë∆∞a 1 link ƒë·ªÉ b·∫°n truy c·∫≠p.

Sau khi m·ªü link tr√™n tr√¨nh duy·ªát ƒë√£ login Github v√† Modal, b·∫°n s·∫Ω c·∫ßn Authorize token API: (·∫£nh)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-authorize.jpg)

Giao di·ªán Modal sau khi ƒë√£ Authorized:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-dashboard.jpg)

Giao di·ªán Terminal sau khi ƒë√£ Authorized:

```s
$ python3 -m modal setup
The `modal` command was not found on your path!
You may need to add it to your path or use `python -m modal` as a workaround.
See more information here:

https://modal.com/docs/guide/troubleshooting#command-not-found-errors

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Was not able to launch web browser
Please go to this URL manually and complete the flow:

https://modal.com/token-flow/tf-XXX

Web authentication finished successfully!
Token is connected to the GITHUB_USERNAME workspace.
Verifying token against https://api.modal.com
Token verified successfully!
Token written to /home/USER_NAME/.modal.toml in profile GITHUB_USERNAME.
```

L√†m theo guide: https://tabby.tabbyml.com/docs/quick-start/installation/modal/

Copy code trong file: https://github.com/TabbyML/tabby/blob/main/website/docs/quick-start/installation/modal/app.py

Trong WSL t·∫°o file `~/tabby-deployment/app.py`, s·ª≠a n·ªôi dung ch·ªó n√†y `allow_concurrent_inputs=200` ƒë·ªÉ tr√°nh l·ªói "c·ª© t·∫°o container m·ªõi" v·ªÅ sau:
```py
@app.function(
    gpu=GPU_CONFIG,
    allow_concurrent_inputs=200,
    container_idle_timeout=120,
    timeout=360,
)
```

### Serve app t·ª´ local l√™n Modal

```s
$ python3 -m modal serve app.py
‚úì Initialized. View run at https://modal.com/apps/GITHUB_USERNAME/main/ap-oOhoNp6GE4ZEyLRG6nPoAj
Building image im-p2iVn8dvfr4jJHHA2vD53Q

...
Built image im-YWVKlo7mQ5FroC5LEIXGxt in 3.78s
‚úì Created objects.
‚îú‚îÄ‚îÄ üî® Created mount /home/USER_NAME/test-modal/app.py
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îî‚îÄ‚îÄ üî® Created web function app_serve => https://GITHUB_USERNAME--tabby-server-app-serve-dev.modal.run
Ô∏èÔ∏è‚ö°Ô∏è Serving... hit Ctrl-C to stop!
‚îî‚îÄ‚îÄ Watching /home/USER_NAME/test-modal.
‚†¥ Running (6 containers finished)... View app at https://modal.com/apps/GITHUB_USERNAME/main/ap-oOhoNp6GE4ZEyLRG6nPoAj
```

V·∫´n gi·ªØ terminal ƒëang ch·∫°y, v√†o link https://GITHUB_USERNAME--tabby-server-app-serve-dev.modal.run

N·∫øu b·∫°n Ctrl+C ·ªü terminal th√¨ n√≥ c≈©ng s·∫Ω terminate c√°i app ƒëang run tr√™n Modal.

### Deploy app t·ª´ local l√™n Modal

```s
$ MODAL_FORCE_BUILD=1 python3.10 -m modal deploy app.py
Building image im-HDPO6oYXTb9cHnaVW5EgDJ
...
Image saved, took 1.55s

Built image im-M0269EbwJ9Hf0prQIHkSQP in 4.66s
‚úì Created objects.
‚îú‚îÄ‚îÄ üî® Created mount /home/USERNAME/test-modal/app.py
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îú‚îÄ‚îÄ üî® Created function download_model.
‚îî‚îÄ‚îÄ üî® Created web function app_serve => https://GITHUB_USERNAME--tabby-server-app-serve.modal.run
‚úì App deployed in 170.844s! üéâ

View Deployment: https://modal.com/apps/GITHUB_USERNAME/main/deployed/tabby-server
```

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-tabby-ui.jpg)

Gi·ªù tr√™n VS Code config l·∫°i c√°c endpoint, token ƒë·ªÉ Tabby tr·ªè ƒë·∫øn. 

T·∫≠n h∆∞·ªüng feature tabAutocomplete r·∫•t th√∫ v·ªã m√† Tabby ƒëem l·∫°i üòò Kh√° nhanh. Kh√¥ng kh√°c g√¨ ch·∫°y local.

1 s·ªë h√¨nh ·∫£nh tr√™n Modal dashboard:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps.jpg)

c√°c th√¥ng s·ªë v√≠ d·ª• nh∆∞ m·ªói container nh·∫≠n Concurrent input l√† 200:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-details.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-files.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps-func-calls.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-logs.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-secrets.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-storage.jpg)

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-apps2.jpg)

tr·∫°ng th√°i idle b·∫°n s·∫Ω ko b·ªã t√≠nh ti·ªÅn:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-modal-idle.jpg)

### M·ªôt s·ªë v·∫•n ƒë·ªÅ m√¨nh ƒëang g·∫∑p ph·∫£i [PENDING]

Persistant data container:

N·∫øu b·∫°n ko d√πng VSCode 1 th·ªùi gian n√≥ s·∫Ω t·ª± ƒë·ªông ƒë∆∞a Modal container Tabby v√†o tr·∫°ng th√°i `idle`.

B·∫°n quay l·∫°i VS Code r·ªìi g√µ 1 c√°i g√¨ ƒë√≥, s·∫Ω trigger request ƒë·∫øn Modal container Tabby v√† launch 1 container m·ªõi.

Nh∆∞ng container n√†y Ko c√≥ data g√¨ c·ªßa b·∫°n. Gi·ªëng ki·ªÉu ko ƒë∆∞·ª£c mount volume v·∫≠y.

B·∫°n s·∫Ω l·∫°i ph·∫£i v√†o link Modal Tabby, t·∫°o l·∫°i account admin, token. R·ªìi v√†o config c·ªßa VS Code extension Tabby - insert token m·ªõi.

ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y th√¨ m√¨nh c·∫ßn ƒë·ªçc th√™m t√†i li·ªáu ·ªü ƒë√¢y:

https://tabby.tabbyml.com/docs/administration/backup/

https://modal.com/docs/guide/cloud-bucket-mounts -> mount bucket s3

https://modal.com/docs/guide/mounting -> upload c·∫£ folder local l√™n

https://modal.com/docs/reference/cli/container -> command l√†m vi·ªác v·ªõi modal container

https://modal.com/docs/guide/secrets#using-secrets -> get secret t·ª´ modal v·ªÅ

Nh∆∞ng v·∫´n ch∆∞a t√¨m ƒë∆∞·ª£c c√°ch ƒë·ªÉ persistent data. ƒê√£ th·ª≠ c√°c h∆∞·ªõng ƒëi sau:

- mount `/data/ee` v√†o s3 nh∆∞ng s·∫Ω b·ªã l·ªói n√†y:

```s
‚†è     3.200 s	Starting...
The application panicked (crashed).
Message:  Must be able to initialize db: migration 35 was previously applied but is missing in the resolved migrations
Location: /root/workspace/ee/tabby-webserver/src/webserver.rs:53
```

- ko d√πng mount m√† upload s·∫µn 1 file `db.sqlite` l√™n s3, trong code `app.py` th√¨ download file ƒë√≥ v·ªÅ folder `/data/ee`. Nh∆∞ng s·∫Ω v·∫´n ko login ƒë∆∞·ª£c v·ªõi account ƒë√£ c√≥ trong `db.sqlite`. Ko hi·ªÉu v√¨ sao.

- m√¨nh nghƒ© l√† do file `db.sqlite` ·ªü m√°y local ko t∆∞∆°ng th√≠ch v·ªõi b·∫£n tr√™n modal n√™n th·ª≠ c√°ch t·∫°o ri√™ng 1 file `upload-db.py` ƒë·ªÉ sau khi app ƒë√£ ch·∫°y th√¨ exec v√†o container upload `db.sqlite` l√™n s3 nh∆∞ n√†y:

    ```s
    ~/tabby-modal-deploy$ python3.10 -m modal container list
                                            Active Containers
    ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
    ‚îÉ Container ID                  ‚îÉ App ID                    ‚îÉ App Name     ‚îÉ Start Time           ‚îÉ
    ‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
    ‚îÇ ta-01J5JT8BEQJSRSPVK717HJA1T9 ‚îÇ ap-4GDFNbZ0vhsI8a3odHpFWb ‚îÇ tabby-server ‚îÇ 2024-08-18 20:21 +07 ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 ls /root
    tabby-modal-deploy

    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 ls /root/tabby-modal-deploy
    __pycache__  app.py  app.py-bk2  app.py.bk  upload-db.py

    ~/tabby-modal-deploy$ python3.10 -m modal container exec ta-01J5JT8BEQJSRSPVK717HJA1T9 python /root/tabby-modal-deploy/upload
    -db.py
    Uploaded /data/ee/db.sqlite to s3://S3_BUCKET_NAME/hoangmnsd/ee/db.sqlite
    ```

  Sau ƒë√≥ deploy l·∫°i app, trong app s·∫Ω download file `db.sqlite` ch√≠nh n√≥ v·ª´a upload l√™n s3. 
  Nh∆∞ng k·∫øt qu·∫£ v·∫´n b·ªã l·ªói ko th·ªÉ login.

Code `app.py` hi·ªán ƒëang nh∆∞ n√†y n·∫øu sau n√†y m√¨nh mu·ªën quay l·∫°i l√†m ti·∫øp:

```py
"""Usage:
modal serve app.py

To force a rebuild by pulling the latest image tag, use:
MODAL_FORCE_BUILD=1 modal serve app.py
"""

import os
from modal import Image, App, asgi_app, gpu, Volume, Secret, CloudBucketMount

IMAGE_NAME = "tabbyml/tabby"
MODEL_ID = "TabbyML/StarCoder-1B"
CHAT_MODEL_ID = "TabbyML/Qwen2-1.5B-Instruct"
EMBEDDING_MODEL_ID = "TabbyML/Nomic-Embed-Text"
GPU_CONFIG = gpu.T4()

TABBY_BIN = "/opt/tabby/bin/tabby"

s3_bucket_name = "tabby-modal"  # Bucket name not ARN.
prefix_ee = 'hoangmnsd/ee/'

def download_model(model_id: str):
    import subprocess

    subprocess.run(
        [
            TABBY_BIN,
            "download",
            "--model",
            model_id,
        ]
    )

def download_file_from_s3(bucket_name: str, object_key: str, file_dir: str, file_name: str):
    import boto3
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"], # these env get from Secret "tabbymodalsyncs3" on Modal
        aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"], # these env get from Secret "tabbymodalsyncs3" on Modal
        region_name=os.environ["AWS_REGION"], # these env get from Secret "tabbymodalsyncs3" on Modal
    )
    local_file_path = file_dir + file_name
    s3.download_file(bucket_name, object_key, local_file_path)
    print(f"Downloaded s3://{bucket_name}/{object_key} to {local_file_path}")

def upload_file_to_s3(bucket_name: str, object_key: str, file_dir: str, file_name: str):
    import boto3
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"], # these env get from Secret "tabbymodalsyncs3" on Modal
        aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"], # these env get from Secret "tabbymodalsyncs3" on Modal
        region_name=os.environ["AWS_REGION"], # these env get from Secret "tabbymodalsyncs3" on Modal
    )
    local_file_path = file_dir + file_name
    s3.upload_file(local_file_path, bucket_name, object_key)
    print(f"Uploaded {local_file_path} to s3://{bucket_name}/{object_key}")

def download_s3():
    specific_file_key = 'hoangmnsd/ee/db.sqlite'
    downloaded_file_name = 'db.sqlite'
    downloaded_file_dir = '/data/ee/'
    download_file_from_s3(s3_bucket_name, specific_file_key, downloaded_file_dir, downloaded_file_name)

def upload_s3():
    specific_file_key = 'hoangmnsd/ee/db.sqlite'
    local_file_name = 'db.sqlite'
    local_file_dir = '/data/ee/'
    upload_file_to_s3(s3_bucket_name, specific_file_key, local_file_dir, local_file_name)

image = (
    Image.from_registry(
        IMAGE_NAME,
        add_python="3.11",
    )
    .dockerfile_commands("ENTRYPOINT []")
    .run_function(download_model, kwargs={"model_id": EMBEDDING_MODEL_ID})
    .run_function(download_model, kwargs={"model_id": CHAT_MODEL_ID})
    .run_function(download_model, kwargs={"model_id": MODEL_ID})
    .pip_install("asgi-proxy-lib")
    .pip_install("boto3")
)

app = App("tabby-server", image=image)

@app.function(
    gpu=GPU_CONFIG,
    allow_concurrent_inputs=200,
    container_idle_timeout=120,
    timeout=360,
    secrets=[Secret.from_name("tabbymodalsyncs3")], # you need to create Secret "tabbymodalsyncs3" on Modal first
)

@asgi_app()
def app_serve():
    import socket
    import subprocess
    import time
    from asgi_proxy import asgi_proxy

    launcher = subprocess.Popen(
        [
            TABBY_BIN,
            "serve",
            "--model",
            MODEL_ID,
            "--chat-model",
            CHAT_MODEL_ID,
            "--port",
            "8000",
            "--device",
            "cuda",
            "--parallelism",
            "1",
        ]
    )

    # Poll until webserver at 127.0.0.1:8000 accepts connections before running inputs.
    def tabby_ready():
        try:
            socket.create_connection(("127.0.0.1", 8000), timeout=1).close()
            return True
        except (socket.timeout, ConnectionRefusedError):
            # Check if launcher webserving process has exited.
            # If so, a connection can never be made.
            retcode = launcher.poll()
            if retcode is not None:
                raise RuntimeError(f"launcher exited unexpectedly with code {retcode}")
            return False

    while not tabby_ready():
        time.sleep(1.0)

    # Wait briefly to allow the "serve" command to initialize
    time.sleep(60)  # Adjust the sleep duration as necessary for your use case
    print("--debug1")
    subprocess.run(["ls", "/data/ee/"])
    # subprocess.run(["mkdir", "-p", "/data/ee"]) # prepare ee dir to prevent error https://stackoverflow.com/a/73193346/9922066
    print("--debug2")
    download_s3()
    subprocess.run(["ls", "/data/ee/"])
    # upload_s3()
    print("Tabby server ready!")
    return asgi_proxy("http://localhost:8000")
```


## 10.5. Install Tabby tr√™n Huggingface Space

HF c√≥ nhi·ªÅu lo·∫°i Plan:
- Pro: account 9$/month
- Space: g·∫ßn nh∆∞ l√† Serverless, set inactive time ƒë·ªÉ container stop n·∫øu ko c√≥ traffic. Free 2 cpu / 16G RAM. Pricing: https://huggingface.co/pricing#spaces
- Inference endpoints: g·∫ßn nh∆∞ Serverless. Pricing: https://huggingface.co/pricing#endpoints

Hi·ªán t·∫°i ƒë·ªÉ d√πng ƒë∆∞·ª£c HF Space c·∫ßn add credit card. HuggingFace hi·ªán v·∫´n ch∆∞a cho ph√©p mua pre-paid Credit b·∫±ng th·∫ª. (Kho·∫£n n√†y k√©m OpenAI)

Guide install Tabby:
- https://tabby.tabbyml.com/docs/quick-start/installation/hugging-face/
- https://huggingface.co/docs/hub/spaces-sdks-docker-tabby

Vi·ªác deploy ƒë∆°n gi·∫£n l√† do Tabby ƒë√£ c√≥ s·∫µn 1 space template v√† ta ·∫•n v√†o link l√† n√≥ t·ª± duplicate space ƒë√≥ lu√¥n. Ch·∫£ ph·∫£i code g√¨

·∫§n v√†o link: https://huggingface.co/spaces/TabbyML/tabby-template-space?duplicate=true

·ªû ƒë√¢y m√¨nh c·ªë t√¨nh ch·ªçn c√°c option FREE ko t√≠nh ti·ªÅn:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-1.jpg)

Ch·ªù container log deploy xong:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-2.jpg)

N·∫øu th·∫•y l·ªói nhi·ªÅu nh∆∞ n√†y, kh·∫£ nƒÉng nguy√™n nh√¢n do m√¨nh ch·ªçn Hardware CPU ko c√≥ GPU:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-containerlog.jpg)

Th·ª≠ s·ª≠a l·∫°i Dockerfile r·ªìi commit l√™n main:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-edit-Dockerfile.jpg)

S·ª≠a xong, commit xong th√¨ nh·ªõ Restart Space ƒë·ªÉ run l·∫°i container:

![](https://d32yh8fbac5ivo.cloudfront.net/static/images/tabby-ai-coding-agent-hf-duplicate-space-restart.jpg)

Sau 1 h·ªìi v·∫´n ko fix ƒë∆∞·ª£c l·ªói n√†y. Ch·ªãu. C√≥ l·∫Ω c·∫ßn ch·ªù Tabby h·ªç release Docker images fix ƒë∆∞·ª£c h·∫øt l·ªói.

N·∫øu mu·ªën b·∫°n c√≥ th·ªÉ th·ª≠ deploy b·∫£n d√πng GPU (m·∫•t ti·ªÅn) ƒë·ªÉ th·ª≠ (Ch·∫Øc s·∫Ω ko c√≥ l·ªói nh∆∞ tr√™n)

## 10.6. Install Tabby tr√™n BentoCloud

Khi ƒëƒÉng k√Ω BentoCloud h·ªç cho tr∆∞·ªõc 10$ credit. Kh√¥ng h√†o ph√≥ng nh∆∞ Modal cho 30$.

https://tabby.tabbyml.com/docs/quick-start/installation/bentoml/

Xem guide c·ªßa Tabby th·∫•y nhi·ªÅu file h∆°n Modal.

L·∫°i c√≤n sync file t·ª´ R2 Cloudflare n·ªØa n√™n ph·∫£i setup nhi·ªÅu th·ª© qu√°, m√¨nh n·∫£n ko mu·ªën l√†m.

D·ªçc k·ªπ th√¨ √Ω t∆∞·ªüng ƒë·ªëi v·ªõi R2 Cloudflare l√† ƒë·ªÉ khi shutdown th√¨ upload `.tabby` database l√™n R2. Khi deploy th√¨ download v·ªÅ ƒë·ªÉ persist database. (**L√† ƒëi·ªÅu m√† trong Guideline Tabby v·ªõi Modal ch∆∞a l√†m**)

# 11. Tabnine

# 12. Blackbox

# 13. Codeium

# REFERENCES

https://dev.to/lunary/7-open-source-ai-projects-to-code-faster-in-2023-2306

Tabby recommend c·∫•u h√¨nh ph·∫ßn c·ª©ng (GPU) cho c√°c model ·ªü ƒë√¢y: https://tabby.tabbyml.com/docs/models/

Tabby x·∫øp h·∫°ng c√°c model ·ªü ƒë√¢y: https://leaderboard.tabbyml.com/

1 s·ªë v√≠ d·ª• ƒë·ªÉ deploy c√°c app c·ªßa b·∫°n l√™n Modal: https://modal.com/docs/examples/web-scraper
