---
title: "K8S 8: Setup Advanced EFK Stack on GCP cluster (ElasticSearch, Fluentd, Kibana)"
date: 2019-11-25T12:42:17+09:00
draft: false
authors: ["hoangmnsd"]
categories: [Tech-Tutorials]
tags: [EFK,Kubernetes,ElasticSearch,Fluentd,Kibana,GCP]
comments: true
toc: true
# below props are for the404blog theme
authorImg: "https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/hoangmsnd-avatar001.jpg"
description: "B√†i n√†y h∆∞·ªõng d·∫´n d·ª±ng EFK stack ph·ª©c t·∫°p h∆°n, d√πng ConfigMap, ElasticSearch chia l√†m c√°c role `master, client, data`, c√≥ √°p d·ª•ng authentication cho Kibana ƒë·ªÉ `more secure`."
---
# Gi·ªõi thi·ªáu
B√†i n√†y h∆∞·ªõng d·∫´n d·ª±ng EFK stack ph·ª©c t·∫°p h∆°n, d√πng ConfigMap,  
ElasticSearch chia l√†m c√°c role "master, client, data",  
c√≥ √°p d·ª•ng authentication cho Kibana ƒë·ªÉ "more secure"

# C√°ch l√†m

ƒê·∫ßu ti√™n c·∫ßn checkout source code n√†y:  
```sh
git clone https://github.com/hoangmnsd/kubernetes-series
cd kubernetes-series/efk-stack-advanced
```

## 1. T·∫°o cluster

Tr√™n gcp th√¨ t·∫°o cluster b·∫±ng console, m√¨nh ƒë√£ ch·ªçn lo·∫°i N1 standard 2 (2vCPU,7.5GB memory), t·∫°o cluster ch·ª©a 2 node nh∆∞ v·∫≠y  
![](https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/gcp-cluster-node-smaller.jpg)

## 2. T·∫°o namespace
```sh
kubectl create -f kube-logging.yaml
```

## 3. T·∫°o ElasticSearch master
>The first node of the cluster we're going to setup is the master which is responsible of controlling the cluster.

```sh
kubectl create -f elasticsearch-master.yaml
```

## 4. T·∫°o ElasticSearch data
>The second node of the cluster we're going to setup is the data which is responsible of hosting the data and executing the queries (CRUD, search, aggregation).

```sh
kubectl create -f elasticsearch-data.yaml
```

## 5. T·∫°o ElasticSearch client
>The last but not least node of the cluster is the client which is responsible of exposing an HTTP interface and pass queries to the data node.

```sh
kubectl create -f elasticsearch-client.yaml
```

Wait for all pods in state `READY 1/1`
```
$ kubectl get pods -A
NAMESPACE      NAME                                                      READY   STATUS    RESTARTS   AGE
default        docker-postgres-cf447b874-p8gbq                           1/1     Running   0          25m
default        docker-spring-boot-containers-7c694df96b-qznth            1/1     Running   0          25m
kube-logging   elasticsearch-client-784cbb477-s7mkq                      1/1     Running   0          2m8s
kube-logging   elasticsearch-data-0                                      1/1     Running   0          2m18s
kube-logging   elasticsearch-master-56fd947c4c-8brls                     1/1     Running   0          2m25s
kube-system    kube-dns-5f886bf8d8-5km8c                                 4/4     Running   0          28m
kube-system    kube-dns-5f886bf8d8-vknfr                                 4/4     Running   0          28m
kube-system    kube-dns-autoscaler-85f8bdb54-d946p                       1/1     Running   0          28m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-3b51bccc-lzpf   1/1     Running   0          28m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-d645c580-blss   1/1     Running   0          28m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-e1ba0508-lk35   1/1     Running   0          28m
kube-system    l7-default-backend-8f479dd9-fx4wg                         1/1     Running   0          28m
kube-system    metrics-server-v0.3.1-8d4c5db46-lqrmp                     2/2     Running   0          28m
kube-system    tiller-deploy-9bf6fb76d-wj229                             1/1     Running   0          26m
```

Ch·ªù 1 v√†i ph√∫t ƒë·ªÉ c√°c pods c·ªßa elastic READY:  

```sh
kubectl logs -f -n kube-logging \
  $(kubectl get pods -n kube-logging | grep elasticsearch-master | sed -n 1p | awk '{print $1}') \
  | grep "Cluster health status changed from \[YELLOW\] to \[GREEN\]"
```

## 6. Generate a password and store in a k8s secret
>We enabled the xpack security module to secure our cluster, so we need to initialise the passwords. Execute the following command which runs the program bin/elasticsearch-setup-passwords within the client node container (any node would work) to generate default users and passwords.

```sh
kubectl exec $(kubectl get pods -n kube-logging | grep elasticsearch-client | sed -n 1p | awk '{print $1}') \
    -n kube-logging \
    -- bin/elasticsearch-setup-passwords auto -b
```
Output
```
$ kubectl exec $(kubectl get pods -n kube-logging | grep elasticsearch-client | sed -n 1p | awk '{print $1}') \
    -n kube-logging \
    -- bin/elasticsearch-setup-passwords auto -b
Changed password for user apm_system
PASSWORD apm_system = eo83yYSKxR49QTx5eNx3

Changed password for user kibana
PASSWORD kibana = tdrr6dMWenSJiOX2eGDN

Changed password for user logstash_system
PASSWORD logstash_system = qf5dXCaYfLJflugUpGtB

Changed password for user beats_system
PASSWORD beats_system = PF75DeqUbWU5TusncL1l

Changed password for user remote_monitoring_user
PASSWORD remote_monitoring_user = 54Nmz6CSaejkcJwgijtP

Changed password for user elastic
PASSWORD elastic = S7kuf4HCinVdMp3Vtrkx
```

Note the `elastic` user password and add it into a k8s secret like this:
```sh
kubectl create secret generic elasticsearch-pw-elastic \
    -n kube-logging \
    --from-literal password=S7kuf4HCinVdMp3Vtrkx
```

## 7. T·∫°o Kibana
```sh
kubectl create -f kibana.yaml
```

## 8. T·∫°o Fluentd
```sh
kubectl create -f fluentd.yaml
```

Wait for all pods in state `READY 1/1`
```
$ kubectl get pods -A
NAMESPACE      NAME                                                      READY   STATUS    RESTARTS   AGE
default        docker-postgres-cf447b874-p8gbq                           1/1     Running   0          29m
default        docker-spring-boot-containers-7c694df96b-qznth            1/1     Running   0          29m
kube-logging   elasticsearch-client-784cbb477-s7mkq                      1/1     Running   0          5m31s
kube-logging   elasticsearch-data-0                                      1/1     Running   0          5m41s
kube-logging   elasticsearch-master-56fd947c4c-8brls                     1/1     Running   0          5m48s
kube-logging   fluentd-c48hz                                             1/1     Running   0          78s
kube-logging   fluentd-j9g7m                                             1/1     Running   0          78s
kube-logging   fluentd-xtk8k                                             1/1     Running   0          78s
kube-logging   kibana-5f8cb9b596-jvllj                                   1/1     Running   0          85s
kube-system    kube-dns-5f886bf8d8-5km8c                                 4/4     Running   0          32m
kube-system    kube-dns-5f886bf8d8-vknfr                                 4/4     Running   0          31m
kube-system    kube-dns-autoscaler-85f8bdb54-d946p                       1/1     Running   0          31m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-3b51bccc-lzpf   1/1     Running   0          31m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-d645c580-blss   1/1     Running   0          31m
kube-system    kube-proxy-gke-efk-stack-tf7-default-pool-e1ba0508-lk35   1/1     Running   0          31m
kube-system    l7-default-backend-8f479dd9-fx4wg                         1/1     Running   0          32m
kube-system    metrics-server-v0.3.1-8d4c5db46-lqrmp                     2/2     Running   0          31m
kube-system    tiller-deploy-9bf6fb76d-wj229                             1/1     Running   0          29m
```

Check logs c·ªßa Fluentd Pod n·∫øu show ra t∆∞∆°ng t·ª± nh∆∞ sau, ko c√≥ error g√¨ l√† ok
```sh
kubectl logs -n kube-logging <POD_NAME> -n kube-logging
# kubectl logs -n kube-logging fluentd-c48hz-n kube-logging
```
output:
```
2019-11-25 03:16:39 +0000 [info]: adding match pattern="fluent.**" type="null"
2019-11-25 03:16:39 +0000 [info]: adding filter pattern="kubernetes.**" type="kubernetes_metadata"
2019-11-25 03:16:39 +0000 [info]: adding match pattern="kubernetes.var.log.containers.**kube-logging**.log" type="null"
2019-11-25 03:16:39 +0000 [info]: adding match pattern="kubernetes.var.log.containers.**kube-system**.log" type="null"
2019-11-25 03:16:39 +0000 [info]: adding match pattern="kubernetes.**" type="elasticsearch"
2019-11-25 03:16:40 +0000 [warn]: #0 Detected ES 7.x or above: `_doc` will be used as the document `_type`.
2019-11-25 03:16:40 +0000 [info]: adding source type="tail"
2019-11-25 03:16:40 +0000 [info]: #0 starting fluentd worker pid=11 ppid=6 worker=0
```

## 9. T·∫°o 1 app li√™n t·ª•c out ra log ƒë·ªÉ test
```sh
kubectl create -f counter.yaml
```

## 10. Test 
Make sure all pods are in `Running` state and `READY` 1/1, 2/2, 3/3, 4/4 ....
```sh
kubectl get pods --all-namespaces
```

get NodePort of service Kibana
```sh
kubectl get svc --all-namespaces
```
output
```
NAMESPACE      NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
default        service/kubernetes             ClusterIP   10.116.0.1      <none>        443/TCP             10m
kube-logging   service/elasticsearch-client   ClusterIP   10.116.9.216    <none>        9200/TCP,9300/TCP   6m34s
kube-logging   service/elasticsearch-data     ClusterIP   10.116.14.205   <none>        9300/TCP            6m46s
kube-logging   service/elasticsearch-master   ClusterIP   10.116.10.136   <none>        9300/TCP            6m56s
kube-logging   service/kibana                 NodePort    10.116.1.237    <none>        5601:32141/TCP      2m15s
kube-system    service/default-http-backend   NodePort    10.116.3.142    <none>        80:32636/TCP        10m
kube-system    service/heapster               ClusterIP   10.116.10.12    <none>        80/TCP              10m
kube-system    service/kube-dns               ClusterIP   10.116.0.10     <none>        53/UDP,53/TCP       10m
kube-system    service/metrics-server         ClusterIP   10.116.12.232   <none>        443/TCP             10m
```
Ta th·∫•y NodePort c·ªßa Kibana l√† `32141`

get external ip of nodes
```sh

kubectl get nodes --output wide
```
output
```
NAME                                                STATUS   ROLES    AGE     VERSION           INTERNAL-IP   EXTERNAL-IP     OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME
gke-efk-stack-advanced-default-pool-eeaed3c6-kx6f   Ready    <none>   9m44s   v1.13.11-gke.14   10.128.0.11   34.67.152.105   Container-Optimized OS from Google   4.14.138+        docker://18.9.7
gke-efk-stack-advanced-default-pool-eeaed3c6-rj79   Ready    <none>   9m44s   v1.13.11-gke.14   10.128.0.12   34.66.70.31     Container-Optimized OS from Google   4.14.138+        docker://18.9.7
```
Ta c√≥ th·ªÉ ch·ªçn 1 Node IP ƒë·ªÉ truy c·∫≠p, v√≠ d·ª• tr√™n th√¨  
`<EXTERNAL-IP>` = `34.67.152.105`   
`<NODOE_PORT>` = `32141`

Create a firewall rule to allow TCP traffic on your node port:
```sh
gcloud compute firewall-rules create kibana-node-port --allow tcp:<NODOE_PORT>
```

N·∫øu ƒë√£ c√≥ s·∫µn th√¨ c·∫ßn update ch·ª© ko th·ªÉ t·∫°o m·ªõi
```sh
gcloud compute firewall-rules update kibana-node-port --allow tcp:<NODOE_PORT>
```

Ho·∫∑c c√°c b·∫°n n√™n m·ªü all NodePort t·ª´ 30000-32767 b·∫±ng command sau:
```sh
gcloud compute firewall-rules update kibana-node-port --allow tcp:30000-32767
```

r·ªìi tr√™n tr√¨nh duy·ªát v√†o `http://<EXTERNAL-IP>:<NODOE_PORT>` ƒë·ªÉ check  

Login b·∫±ng user `elastic` v√† passw ƒë√£ generate ·ªü step tr√™n

T·∫°o index-pattern : `logstash-*`

V√†o Discover, check logs N·∫øu ch·ªâ show log c·ªßa namespace `default` l√† Done!

N·∫øu mu·ªën s·ª≠a ConfigMap c·ªßa Fluentd th√¨ c·∫ßn ch√∫ √Ω l√† sau khi s·ª≠a xong th√¨ sau khi `apply` template m·ªõi,  
b·∫°n ph·∫£i delete c√°c pods fluentd c≈© ƒë·ªÉ n√≥ apply c√°c config v·ª´a thay ƒë·ªïi

## 11. D√πng Helm ƒë·ªÉ deploy

·ªû c√°c b∆∞·ªõc t·ª´ 1-10 tr√™n ƒë√£ h∆∞·ªõng d·∫´n setup EFK b·∫±ng tay r·ªìi.  
Gi·ªù n·∫øu mu·ªën d√πng Helm th√¨ c·∫ßn thay ƒë·ªïi 1 s·ªë ch·ªó. C·ª• th·ªÉ c√°c b∆∞·ªõc tr√™n th√¨ c√≥ b∆∞·ªõc 6: Generate ra password l√† lo·∫≥ng ngo·∫±ng nh·∫•t,  
mu·ªën chuy·ªÉn sang t·ª± ƒë·ªông b·∫±ng Helm th√¨ c·∫ßn s·ª≠a c√°c file:  
`elasticsearch-client.yaml` (ch·ªß y·∫øu file n√†y),  
`fluentd.yaml`,  
`kibana.yaml`  
![](https://raw.githubusercontent.com/hoangmnsd/images-bucket/master/static/images/efk-es-client-diff.jpg)

Sau khi s·ª≠a xong th√¨ ch·ªâ c·∫ßn l√†m nh∆∞ sau l√† deploy c·∫£ h·ªá th·ªëng EFK advanced l√™n trong 1 n·ªët nh·∫°c üòÜ

```sh
# Ch√∫ √Ω l√† c·∫ßn c√†i ƒë·∫∑t helm v√† tiller ƒë√£ (c√≥ th·ªÉ tham kh·∫£o b√†i tr∆∞·ªõc K8S 5: Using Helm ...)
cd kubernetes-series/efk-stack-advanced-helm
helm install -n efk-stack .
```
Ch·ªù kho·∫£ng 5ph√∫t, r·ªìi quay l·∫°i step 10 ƒë·ªÉ Test h·ªá th·ªëng, ch√∫ √Ω l√† ƒëƒÉng nh·∫≠p kibana b·∫±ng user `my_admin`

DONE! üéâüéâüéâ

**REFERENCES**:  
https://kauri.io/article/e5b86351f38940b8a071267062f052cb/v2/monitoring-kubernetes-with-elastic-stack-2.-elasticsearch-and-kibana  
https://github.com/gjeanmart/kauri-content/blob/master/spring-boot-simple/k8s  
https://blog.ptrk.io/tweaking-an-efk-stack-on-kubernetes/  
https://github.com/GoogleCloudPlatform/click-to-deploy/tree/master/k8s/elastic-gke-logging  


